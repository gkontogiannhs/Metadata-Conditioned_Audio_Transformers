seed: 42

dataset:
  name: icbhi
  data_folder: /home/AIoT04/Datasets/icbhi_dataset
  cycle_metadata_path: /home/AIoT04/Datasets/icbhi_dataset/icbhi_metadata.csv
  class_split: lungsound
  split_strategy: official # official, foldwise, random (patient-wise random)
  test_fold: 0
  multi_label: true
  n_cls: 4
  weighted_sampler: true
  batch_size: 16
  num_workers: 2
  h: 128
  w: 1024

audio:
  # audio basics
  sample_rate: 16000
  desired_length: 10.0
  remove_dc: true
  normalize: false
  # padding type: zero, repeat
  pad_type: repeat
  # fade settings
  use_fade: true
  fade_samples_ratio: 64
  # features
  n_mels: 128
  frame_length: 40
  frame_shift: 10
  low_freq: 100
  high_freq: 8000
  window_type: hanning
  use_energy: false
  dither: 0.0
  mel_norm: mit # hf, mit, None
  
  resz: 1.0 # spectrogram resize factor (1.0 = no resize)
  # Augmentation
  raw_augment: 1
  wave_aug:
    - type: Crop
      sampling_rate: 16000
      zone: [0.0, 1.0]
      coverage: 1.0
      p: 0.0

    - type: Noise
      color: white
      p: 0.1

    - type: Speed
      factor: [0.9, 1.1]
      p: 0.1

    - type: Loudness
      factor: [0.5, 2.0]
      p: .1

    - type: VTLP
      sampling_rate: 16000
      zone: [0.0, 1.0]
      fhi: 4800
      factor: [0.9, 1.1]
      p: 0.1

    - type: Pitch
      sampling_rate: 16000
      factor: [-1, 3]
      p: 0.0

  spec_aug:
    - type: SpecAugment
      policy: icbhi_ast_sup
      mask: zero
      p: .3

models:
  # simplerespcnn:
  #   # name: simplerespcnn
  #   label_dim: 4

  # cnn6:
  #   name: cnn6
  #   do_dropout: true
  #   label_dim: 4
  #   backbone_only: false
  #   cpt_path: /home/AIoT04/Dev/pretrained_models/Cnn6_mAP=0.343.pth

  ast:
    name: ast
    audioset_pretrain: true
    input_fdim: 128
    input_tdim: 1024
    model_size: base384
    fstride: 10
    tstride: 10
    imagenet_pretrain: true
    label_dim: 2
    backbone_only: false
    audioset_ckpt_path: /home/AIoT04/Dev/pretrained_models/audioset_10_10_0.4593.pth
    dropout: 0.0

  ast_proj:
    name: ast_proj
    audioset_pretrain: true
    input_fdim: 128
    input_tdim: 1024
    model_size: base384
    fstride: 10
    tstride: 10
    imagenet_pretrain: true
    label_dim: 2
    audioset_ckpt_path: /home/AIoT04/Dev/pretrained_models/audioset_10_10_0.4593.pth
    dropout: 0.3
    dev_emb_dim: 4
    site_emb_dim: 4
    hidden_dim: 64

  ast_film:
    name: ast_film
    audioset_pretrain: true
    input_fdim: 128
    input_tdim: 1024
    model_size: base384
    fstride: 10
    tstride: 10
    imagenet_pretrain: true
    label_dim: 2
    audioset_ckpt_path: /home/AIoT04/Dev/pretrained_models/audioset_10_10_0.4593.pth
    dropout: 0.0
    dev_emb_dim: 4
    site_emb_dim: 7
    metadata_hidden_dim: 32
    film_hidden_dim: 32
    conditioned_layers: [12]
    condition_on_device: True
    condition_on_site: True
    condition_on_rest: True

  ast_filmpp:
    name: ast_filmpp
    audioset_pretrain: true
    input_fdim: 128
    input_tdim: 1024
    model_size: base384
    fstride: 10
    tstride: 10
    imagenet_pretrain: true
    label_dim: 2
    audioset_ckpt_path: /home/AIoT04/Dev/pretrained_models/audioset_10_10_0.4593.pth
    dropout: 0.0
    dev_emb_dim: 4
    site_emb_dim: 7
    metadata_hidden_dim: 16
    film_hidden_dim: 16
    conditioned_layers: [12]
    D_dev: 32
    D_site: 32

training:
  # model_name: ast
  n_cls: 2
  loss: cross_entropy # cross_entropy, weighted_ce, focal, label_smoothing
  # alpha: 0.25
  gamma: 2.0
  use_class_weights: false
  epochs: 1
  kfold_splits: 5
  early_stopping: 15
  grad_clip: 1.0

  hardware:
    visible_gpus: "0, 1, 2, 3, 4, 5, 6, 7, 8, 9"   # which GPUs to expose
    device_id: 6          # which GPU among visible ones to use
    use_dataparallel: false    # enable/disable DataParallel

  optimizer:
    type: adamw
    lr: 3e-5 # 3e-5 * batch_size/8
    weight_decay: 0.05 # only used if scheduler.cosine_weight_decay=false
    # momentum:
    # betas: # [0.9, 0.95]
    cosine_weight_decay: true
    final_weight_decay: 0.0

  scheduler:
    type: cosine_warmup        # options: none, cosine, cosine_warmup, reduce_on_plateau, cosine_warmup_restarts
    warmup_epochs: 0         # used only for warmup
    T_0: 20               # used only for cosine_*
    start_linear_warmup: 1e-4
    end_linear_warmup: 1
    min_lr: 1e-8

    reduce_factor: 0.5        # used for ReduceLROnPlateau
    reduce_patience: 2
    reduce_min_lr: 1e-8
    reduce_metric: "val_loss"  # metric to monitor
    reduce_mode: "min"        # or "min", depending on metric (e.g., loss=min)

mlflow:
  tracking_uri:
  tracking_username:
  tracking_password:
  experiment_name:
