seed: 42

dataset:
  name: icbhi
  data_folder: /home/AIoT04/Datasets/icbhi_dataset
  class_split: lungsound
  split_strategy: official # official, foldwise, random (patient-wise random)
  test_fold: 0
  n_cls: 4
  weighted_sampler: true
  batch_size: 8
  num_workers: 4
  h: 128
  w: 1024

audio:
  # audio basics
  sample_rate: 16000
  desired_length: 10.0
  # padding type: zero, repeat, aug
  pad_type: repeat
  # fade settings
  use_fade: true
  fade_samples_ratio: 64
  # features
  n_mels: 128
  frame_length: 25
  frame_shift: 10
  low_freq: 100
  high_freq: 8000
  window_type: hanning
  use_energy: false
  dither: 0.0
  mel_norm: mit # hf, mit, None
  
  resz: 1.0 # spectrogram resize factor (1.0 = no resize)
  # Augmentation
  raw_augment: 0
  wave_aug:
    - type: Crop
      sampling_rate: 16000
      zone: [0.0, 1.0]
      coverage: 1.0
      p: 0.0

    - type: Noise
      color: white
      p: 0.0

    - type: Speed
      factor: [0.9, 1.1]
      p: 0.0

    - type: Loudness
      factor: [0.5, 2.0]
      p: .1

    - type: VTLP
      sampling_rate: 16000
      zone: [0.0, 1.0]
      fhi: 4800
      factor: [0.9, 1.1]
      p: 0.1

    - type: Pitch
      sampling_rate: 16000
      factor: [-1, 3]
      p: 0.0

  spec_aug:
    - type: SpecAugment
      policy: icbhi_ast_sup
      mask: mean
      p: .2

models:
  # simplerespcnn:
  #   # name: simplerespcnn
  #   label_dim: 4

  # cnn6:
  #   name: cnn6
  #   do_dropout: true
  #   label_dim: 4
  #   backbone_only: false
  #   cpt_path: /home/AIoT04/Dev/pretrained_models/Cnn6_mAP=0.343.pth

  ast:
    name: ast
    audioset_pretrain: true
    input_fdim: 128
    input_tdim: 1024
    model_size: base384
    fstride: 10
    tstride: 10
    imagenet_pretrain: true
    label_dim: 4
    backbone_only: false
    audioset_ckpt_path: /home/AIoT04/Dev/pretrained_models/audioset_10_10_0.4593.pth
    dropout: 0.5

training:
  model_name: ast

  loss: weighted_ce # cross_entropy, weighted_ce, focal, label_smoothing
  gamma: 1.5
  use_class_weights: true
  epochs: 100
  kfold_splits: 5
  early_stopping: 15
  grad_clip: 1.0

  hardware:
    visible_gpus: "2,3"   # which GPUs to expose
    device_id: 0              # which GPU among visible ones to use
    use_dataparallel: true    # enable/disable DataParallel


  optimizer:
    type: adamw
    lr: 3e-5 # 3e-5 * batch_size/8
    weight_decay: 0.05 # only used if scheduler.cosine_weight_decay=false
    momentum:
    betas: [0.9, 0.95]

  scheduler:
    type: cosine_warmup        # options: none, cosine, cosine_warmup, reduce_on_plateau
    warmup_epochs: 10         # used only for warmup
    start_linear_warmup: 1e-5
    end_linear_warmup: 1e-2
    min_lr: 1e-8
    cosine_weight_decay: true
    final_weight_decay: 0.0

    reduce_factor: 0.5        # used for ReduceLROnPlateau
    reduce_patience: 3
    reduce_min_lr: 1e-8
    reduce_metric: "icbhi_score"  # metric to monitor
    reduce_mode: "max"        # or "min", depending on metric (e.g., loss=min)


mlflow:
  tracking_uri:
  tracking_username:
  tracking_password:
  experiment_name:
