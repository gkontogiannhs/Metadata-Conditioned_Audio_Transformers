seed: 42

dataset:
  name: icbhi
  data_folder: /home/AIoT04/Datasets/icbhi_dataset
  cycle_metadata_path: /home/AIoT04/Datasets/icbhi_dataset/icbhi_metadata.csv
  class_split: lungsound
  split_strategy: official # official, foldwise, random (patient-wise random)
  test_fold: 0
  multi_label: true
  n_cls: 4
  weighted_sampler: false
  batch_size: 16
  num_workers: 0
  h: 128
  w: 1024

audio:
  # audio basics
  sample_rate: 16000
  desired_length: 10.0
  remove_dc: true
  normalize: false
  # padding type: zero, repeat
  pad_type: repeat
  # fade settings
  use_fade: true
  fade_samples_ratio: 64
  # features
  n_mels: 128
  frame_length: 40
  frame_shift: 10
  low_freq: 100
  high_freq: 8000
  window_type: hanning
  use_energy: false
  dither: 0.0
  mel_norm: mit # hf, mit, None
  
  resz: 1.0 # spectrogram resize factor (1.0 = no resize)
  # Augmentation
  raw_augment: 1
  wave_aug:
    - type: Crop
      sampling_rate: 16000
      zone: [0.0, 1.0]
      coverage: 1.0
      p: 0.0

    - type: Noise
      color: white
      p: 0.1

    - type: Speed
      factor: [0.9, 1.1]
      p: 0.1

    - type: Loudness
      factor: [0.5, 2.0]
      p: .1

    - type: VTLP
      sampling_rate: 16000
      zone: [0.0, 1.0]
      fhi: 4800
      factor: [0.9, 1.1]
      p: 0.1

    - type: Pitch
      sampling_rate: 16000
      factor: [-1, 3]
      p: 0.0

  spec_aug:
    - type: SpecAugment
      policy: icbhi_ast_sup
      mask: zero
      p: .3

models:
  ast_meta_proj:
    name: ast_meta_proj
    # AST settings
    audioset_pretrain: true
    input_fdim: 128
    input_tdim: 1024
    model_size: base384
    fstride: 10
    tstride: 10
    imagenet_pretrain: true
    label_dim: 2
    audioset_ckpt_path: /home/AIoT04/Dev/pretrained_models/audioset_10_10_0.4593.pth
    dropout: 0.4
    
    # Metadata projection settings
    dev_emb_dim: 8
    site_emb_dim: 14
    hidden_dim: 32
    dropout_p: 0.4
    init_gate: 0.5
    
    # Ablation flags
    use_device: true
    use_site: true
    use_continuous: true
    use_missing_flags: false

training:
  # model_name: ast
  n_cls: 4
  loss: bce # bce, weighted_ce, focal, label_smoothing, asymmetric, hierarchical, composite
  sensitivity_bias: 1.5
  alpha: 0.25
  gamma: 2.0
  use_class_weights: false
  epochs: 50
  kfold_splits: 5
  early_stopping: 5
  grad_clip: 1.0

  # AST Freezing
  freeze:
    strategy: trainable_blocks  # none, all, until_block, trainable_blocks
    trainable_blocks: 8        # Number of blocks to keep trainable (from end)
    until_block:            # Alternative: freeze blocks 0-9


  # Loss-specific parameters (for hierarchical/composite)
  partial_credit: 0.5
  miss_penalty: 2.0
  over_pred_cost: 0.3

  hardware:
    visible_gpus: "0, 1, 2, 3, 4, 5, 6"   # which GPUs to expose
    device_id: 3          # which GPU among visible ones to use
    use_dataparallel: false    # enable/disable DataParallel

  optimizer:
    type: adamw
    lr: 3e-5
    weight_decay: 0.05 # only used if scheduler.cosine_weight_decay=false
    # momentum:
    # betas: # [0.9, 0.95]
    cosine_weight_decay: true
    final_weight_decay: 0.0

  scheduler:
    type: cosine_warmup        # options: none, cosine, cosine_warmup, reduce_on_plateau, cosine_warmup_restarts
    warmup_epochs: 10         # used only for warmup
    T_0: 20               # used only for cosine_*
    start_linear_warmup: 1e-4
    end_linear_warmup: 1
    min_lr: 1e-8

    reduce_factor: 0.5        # used for ReduceLROnPlateau
    reduce_patience: 2
    reduce_min_lr: 1e-8
    reduce_metric: "val_loss"  # metric to monitor
    reduce_mode: "min"        # or "min", depending on metric (e.g., loss=min)

mlflow:
  tracking_uri:
  tracking_username:
  tracking_password:
  experiment_name:
