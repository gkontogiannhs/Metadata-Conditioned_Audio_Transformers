{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd2d02fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of AST model, mostly adapted from https://github.com/YuanGongND/AST\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from timm.models.layers import to_2tuple, trunc_normal_\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "481d57ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c63d1317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# override the timm package to relax the input shape constraint.\n",
    "class PatchEmbed(nn.Module):\n",
    "    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=768):\n",
    "        super().__init__()\n",
    "\n",
    "        img_size = to_2tuple(img_size)\n",
    "        patch_size = to_2tuple(patch_size)\n",
    "        num_patches = (img_size[1] // patch_size[1]) * (img_size[0] // patch_size[0])\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.num_patches = num_patches\n",
    "\n",
    "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.proj(x).flatten(2).transpose(1, 2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c24cfcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 768])\n"
     ]
    }
   ],
   "source": [
    "image = torch.randn(1, 1, 128, 1024).to(DEVICE)\n",
    "\n",
    "PE = PatchEmbed(patch_size=(16, 16), in_chans=1, embed_dim=768).to(DEVICE)\n",
    "patches = PE(image)\n",
    "print(patches.shape)  # torch.Size([1, 512, 768])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7c96b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASTModel(nn.Module):\n",
    "    \"\"\"\n",
    "    The AST model.\n",
    "    :param label_dim: the label dimension, i.e., the number of total classes, it is 527 for AudioSet, 50 for ESC-50, and 35 for speechcommands v2-35\n",
    "    :param fstride: the stride of patch spliting on the frequency dimension, for 16*16 patchs, fstride=16 means no overlap, fstride=10 means overlap of 6\n",
    "    :param tstride: the stride of patch spliting on the time dimension, for 16*16 patchs, tstride=16 means no overlap, tstride=10 means overlap of 6\n",
    "    :param input_fdim: the number of frequency bins of the input spectrogram\n",
    "    :param input_tdim: the number of time frames of the input spectrogram\n",
    "    :param imagenet_pretrain: if use ImageNet pretrained model\n",
    "    :param audioset_pretrain: if use full AudioSet and ImageNet pretrained model\n",
    "    :param audioset_ckpt_path: path to AudioSet pretrained checkpoint\n",
    "    :param model_size: the model size of AST, should be in [tiny224, small224, base224, base384]\n",
    "    :param verbose: print model summary\n",
    "    :param backbone_only: if True, do not create classification head\n",
    "    :param dropout_p: dropout probability for regularization\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            label_dim=4, \n",
    "            fstride=10, \n",
    "            tstride=10, \n",
    "            input_fdim=128, \n",
    "            input_tdim=1024,\n",
    "            imagenet_pretrain=True,\n",
    "            audioset_pretrain=False,\n",
    "            audioset_ckpt_path='',\n",
    "            model_size='base384', \n",
    "            verbose=True, \n",
    "            backbone_only=False,\n",
    "            dropout_p=0.3,\n",
    "        ):\n",
    "\n",
    "        super(ASTModel, self).__init__()\n",
    "        assert timm.__version__ == '0.4.5', 'Please use timm == 0.4.5, the code might not be compatible with newer versions.'\n",
    "\n",
    "        if verbose == True:\n",
    "            print('---------------AST Model Summary---------------')\n",
    "            print('ImageNet pretraining: {:s}, AudioSet pretraining: {:s}'.format(str(imagenet_pretrain),str(audioset_pretrain)))\n",
    "        \n",
    "        # override timm input shape restriction\n",
    "        timm.models.vision_transformer.PatchEmbed = PatchEmbed\n",
    "        self.label_dim = label_dim\n",
    "        self.reg_dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "        # if AudioSet pretraining is not used (but ImageNet pretraining may still apply)\n",
    "        if audioset_pretrain == False:\n",
    "            if model_size == 'tiny224':\n",
    "                self.v = timm.create_model('vit_deit_tiny_distilled_patch16_224', pretrained=imagenet_pretrain)\n",
    "            elif model_size == 'small224':\n",
    "                self.v = timm.create_model('vit_deit_small_distilled_patch16_224', pretrained=imagenet_pretrain)\n",
    "            elif model_size == 'base224':\n",
    "                self.v = timm.create_model('vit_deit_base_distilled_patch16_224', pretrained=imagenet_pretrain)\n",
    "            elif model_size == 'base384':\n",
    "                self.v = timm.create_model('vit_deit_base_distilled_patch16_384', pretrained=imagenet_pretrain)\n",
    "            else:\n",
    "                raise Exception('Model size must be one of tiny224, small224, base224, base384.')\n",
    "            \n",
    "            if verbose:\n",
    "                print('Vision transformer model size {:s} created.'.format(model_size))\n",
    "            \n",
    "            self.original_num_patches = self.v.patch_embed.num_patches\n",
    "            self.oringal_hw = int(self.original_num_patches ** 0.5)\n",
    "            self.original_embedding_dim = self.v.pos_embed.shape[2]\n",
    "\n",
    "            self.mlp_head = None\n",
    "            if not backbone_only:\n",
    "                print('Creating classification head with hidden dim 64 and dropout p={:.2f}'.format(dropout_p))\n",
    "                self.mlp_head = nn.Sequential(\n",
    "                    nn.LayerNorm(self.original_embedding_dim), \n",
    "                    self.reg_dropout,\n",
    "                    nn.Linear(self.original_embedding_dim, 64),  # Hidden layer\n",
    "                    nn.ReLU(),\n",
    "                    self.reg_dropout,\n",
    "                    nn.Linear(64, self.label_dim)  # label_dim outputs, no activation here\n",
    "                )\n",
    "\n",
    "            # automatcially get the intermediate shape\n",
    "            f_dim, t_dim = self.get_shape(fstride, tstride, input_fdim, input_tdim)\n",
    "            num_patches = f_dim * t_dim\n",
    "            self.v.patch_embed.num_patches = num_patches\n",
    "            if verbose == True:\n",
    "                print('frequency stride={:d}, time stride={:d}'.format(fstride, tstride))\n",
    "                print('number of patches={:d}'.format(num_patches))\n",
    "\n",
    "            # the linear projection layer\n",
    "            new_proj = torch.nn.Conv2d(1, self.original_embedding_dim, kernel_size=(16, 16), stride=(fstride, tstride))\n",
    "            if imagenet_pretrain == True:\n",
    "                new_proj.weight = torch.nn.Parameter(torch.sum(self.v.patch_embed.proj.weight, dim=1).unsqueeze(1))\n",
    "                new_proj.bias = self.v.patch_embed.proj.bias\n",
    "            self.v.patch_embed.proj = new_proj\n",
    "\n",
    "            # the positional embedding\n",
    "            if imagenet_pretrain == True:\n",
    "                # get the positional embedding from deit model, skip the first two tokens (cls token and distillation token), reshape it to original 2D shape (24*24).\n",
    "                new_pos_embed = self.v.pos_embed[:, 2:, :].detach().reshape(1, self.original_num_patches, self.original_embedding_dim).transpose(1, 2).reshape(1, self.original_embedding_dim, self.oringal_hw, self.oringal_hw)\n",
    "                # cut (from middle) or interpolate the second dimension of the positional embedding\n",
    "                if t_dim <= self.oringal_hw:\n",
    "                    new_pos_embed = new_pos_embed[:, :, :, int(self.oringal_hw / 2) - int(t_dim / 2): int(self.oringal_hw / 2) - int(t_dim / 2) + t_dim]\n",
    "                else:\n",
    "                    new_pos_embed = torch.nn.functional.interpolate(new_pos_embed, size=(self.oringal_hw, t_dim), mode='bilinear')\n",
    "                # cut (from middle) or interpolate the first dimension of the positional embedding\n",
    "                if f_dim <= self.oringal_hw:\n",
    "                    new_pos_embed = new_pos_embed[:, :, int(self.oringal_hw / 2) - int(f_dim / 2): int(self.oringal_hw / 2) - int(f_dim / 2) + f_dim, :]\n",
    "                else:\n",
    "                    new_pos_embed = torch.nn.functional.interpolate(new_pos_embed, size=(f_dim, t_dim), mode='bilinear')\n",
    "                # flatten the positional embedding\n",
    "                new_pos_embed = new_pos_embed.reshape(1, self.original_embedding_dim, num_patches).transpose(1,2)\n",
    "                # concatenate the above positional embedding with the cls token and distillation token of the deit model.\n",
    "                self.v.pos_embed = nn.Parameter(torch.cat([self.v.pos_embed[:, :2, :].detach(), new_pos_embed], dim=1))\n",
    "            else:\n",
    "                # if not use imagenet pretrained model, just randomly initialize a learnable positional embedding\n",
    "                # TODO can use sinusoidal positional embedding instead\n",
    "                new_pos_embed = nn.Parameter(torch.zeros(1, self.v.patch_embed.num_patches + 2, self.original_embedding_dim))\n",
    "                self.v.pos_embed = new_pos_embed\n",
    "                trunc_normal_(self.v.pos_embed, std=.02)\n",
    "\n",
    "        # now load a model that is pretrained on both ImageNet and AudioSet\n",
    "        elif audioset_pretrain == True:\n",
    "            if audioset_pretrain == True and imagenet_pretrain == False:\n",
    "                raise ValueError('currently model pretrained on only audioset is not supported, please set imagenet_pretrain = True to use audioset pretrained model.')\n",
    "            if model_size != 'base384':\n",
    "                raise ValueError('currently only has base384 AudioSet pretrained model.')\n",
    "            \n",
    "            if not os.path.exists(audioset_ckpt_path):\n",
    "                raise FileNotFoundError(f\"Pretrained AudioSet model not found at '{audioset_ckpt_path}'.\")\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"Loading AudioSet pretrained model from {audioset_ckpt_path}\")\n",
    "            \n",
    "            # Load checkpoint\n",
    "            sd = torch.load(audioset_ckpt_path, map_location=DEVICE)\n",
    "            \n",
    "            # Create temporary model to load AudioSet weights\n",
    "            audio_model = ASTModel(\n",
    "                label_dim=label_dim,\n",
    "                fstride=fstride, \n",
    "                tstride=tstride, \n",
    "                input_fdim=input_fdim, \n",
    "                input_tdim=input_tdim, \n",
    "                imagenet_pretrain=False, \n",
    "                audioset_pretrain=False,\n",
    "                backbone_only=backbone_only,\n",
    "                model_size='base384', \n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            # Handle different checkpoint formats (with or without DataParallel)\n",
    "            model_dict = audio_model.state_dict()\n",
    "            pretrained_dict = {}\n",
    "            \n",
    "            for k, v in sd.items():\n",
    "                # Remove various prefixes\n",
    "                if k.startswith('module.'):\n",
    "                    key = k[7:]  # Remove 'module.' prefix (DataParallel)\n",
    "                else:\n",
    "                    key = k\n",
    "                \n",
    "                # Keep trained weights only for the vision transformer backbone\n",
    "                # Skip mlp_head weights since dimensions differ\n",
    "                if key in model_dict:\n",
    "                    if model_dict[key].shape == v.shape:\n",
    "                        pretrained_dict[key] = v\n",
    "                    elif verbose:\n",
    "                        print(f\"Shape mismatch for {key}: model={model_dict[key].shape}, ckpt={v.shape}\")\n",
    "                print(\"No mismatch for key:\", key) if verbose else None\n",
    "                print(\"No mlp_head weights loaded from AudioSet checkpoint.\") if verbose else None\n",
    "            if len(pretrained_dict) > 0:\n",
    "                model_dict.update(pretrained_dict)\n",
    "                audio_model.load_state_dict(model_dict)\n",
    "                if verbose:\n",
    "                    print(f\"Loaded {len(pretrained_dict)}/{len(model_dict)} tensors from AudioSet checkpoint\")\n",
    "                    print(f\"The remaining {len(model_dict) - len(pretrained_dict)} tensors are randomly initialized and will be trained from scratch.\")\n",
    "            else:\n",
    "                raise RuntimeError(\"No matching weights found in checkpoint!\")\n",
    "            \n",
    "            # Extract the vision transformer backbone\n",
    "            self.v = audio_model.v\n",
    "            self.original_num_patches = self.v.patch_embed.num_patches\n",
    "            self.oringal_hw = int(self.original_num_patches ** 0.5)\n",
    "            self.original_embedding_dim = self.v.pos_embed.shape[2]\n",
    "            \n",
    "            # Create new classification head for your task\n",
    "            self.mlp_head = None\n",
    "            if not backbone_only:\n",
    "                print('Creating classification head with hidden dim 64 and dropout p={:.2f}'.format(dropout_p))\n",
    "                self.mlp_head = nn.Sequential(\n",
    "                    nn.LayerNorm(self.original_embedding_dim), \n",
    "                    self.reg_dropout,\n",
    "                    nn.Linear(self.original_embedding_dim, 64),  # Hidden layer\n",
    "                    nn.ReLU(),\n",
    "                    self.reg_dropout,\n",
    "                    nn.Linear(64, self.label_dim)  # 2 outputs (no sigmoid here, apply in loss)\n",
    "                )\n",
    "\n",
    "            # Get patch dimensions for your input\n",
    "            f_dim, t_dim = self.get_shape(fstride, tstride, input_fdim, input_tdim)\n",
    "            num_patches = f_dim * t_dim\n",
    "            self.v.patch_embed.num_patches = num_patches\n",
    "            if verbose == True:\n",
    "                print('frequency stride={:d}, time stride={:d}'.format(fstride, tstride))\n",
    "                print('number of patches={:d}'.format(num_patches))\n",
    "\n",
    "            # Adapt positional embeddings from AudioSet (12x101) to your dimensions\n",
    "            new_pos_embed = self.v.pos_embed[:, 2:, :].detach().reshape(1, 1212, 768).transpose(1, 2).reshape(1, 768, 12, 101)\n",
    "            # if the input sequence length is larger than the original audioset (10s), then cut the positional embedding\n",
    "            if t_dim < 101:\n",
    "                new_pos_embed = new_pos_embed[:, :, :, 50 - int(t_dim/2): 50 - int(t_dim/2) + t_dim]\n",
    "            # otherwise interpolate\n",
    "            else:\n",
    "                new_pos_embed = torch.nn.functional.interpolate(new_pos_embed, size=(12, t_dim), mode='bilinear')\n",
    "            if f_dim < 12:\n",
    "                new_pos_embed = new_pos_embed[:, :, 6 - int(f_dim/2): 6 - int(f_dim/2) + f_dim, :]\n",
    "            # otherwise interpolate\n",
    "            elif f_dim > 12:\n",
    "                new_pos_embed = torch.nn.functional.interpolate(new_pos_embed, size=(f_dim, t_dim), mode='bilinear')\n",
    "            new_pos_embed = new_pos_embed.reshape(1, 768, num_patches).transpose(1, 2)\n",
    "            self.v.pos_embed = nn.Parameter(torch.cat([self.v.pos_embed[:, :2, :].detach(), new_pos_embed], dim=1))\n",
    "\n",
    "    def get_shape(self, fstride, tstride, input_fdim=128, input_tdim=1024):\n",
    "        test_input = torch.randn(1, 1, input_fdim, input_tdim)\n",
    "        test_proj = nn.Conv2d(1, self.original_embedding_dim, kernel_size=(16, 16), stride=(fstride, tstride))\n",
    "        test_out = test_proj(test_input)\n",
    "        f_dim = test_out.shape[2]\n",
    "        t_dim = test_out.shape[3]\n",
    "        return f_dim, t_dim\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        \"\"\"\n",
    "        Extract features from the backbone.\n",
    "        :param x: input spectrogram, shape (B, 1, F, T)\n",
    "        :return: feature embeddings\n",
    "        \"\"\"\n",
    "        B = x.shape[0]\n",
    "        x = self.v.patch_embed(x)\n",
    "        print(f\"Images size after patch embedding: {x.shape}\")\n",
    "        print(f\"CLS token shape: {self.v.cls_token.shape}\")\n",
    "        cls_tokens = self.v.cls_token.expand(B, -1, -1)\n",
    "        print(f\"Expanded CLS token shape: {cls_tokens.shape}\")\n",
    "        dist_token = self.v.dist_token.expand(B, -1, -1)\n",
    "        print(f\"Expanded distillation token shape: {dist_token.shape}\")\n",
    "        x = torch.cat((cls_tokens, dist_token, x), dim=1)\n",
    "        print(f\"Shape after concatenating tokens: {x.shape}\")\n",
    "        x = x + self.v.pos_embed\n",
    "        print(f\"Positional embedding shape: {self.v.pos_embed.shape}\")\n",
    "        x = self.v.pos_drop(x)\n",
    "        print(x.shape)\n",
    "\n",
    "        for blk in self.v.blocks:\n",
    "            x = blk(x)\n",
    "        print(f\"x.shape after blocks: {x.shape}\")\n",
    "\n",
    "        x = self.v.norm(x)\n",
    "        print(f\"x.shape after norm: {x.shape}\") # (B, Patches+2, Embedding_dim)\n",
    "        x = (x[:, 0, :] + x[:, 1, :]) / 2  # average CLS and distillation tokens -> (B, Embedding_dim)\n",
    "        print(f\"x.shape after averaging tokens: {x.shape}\")\n",
    "        return x\n",
    "\n",
    "    @torch.amp.autocast(device_type=DEVICE.type)\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: input spectrogram\n",
    "                  Can be either (B, T, F) [original format] or (B, 1, F, T) [preprocessed]\n",
    "        :return: prediction logits or features if backbone_only\n",
    "        \"\"\"\n",
    "        # Handle both input formats\n",
    "        if x.dim() == 3:  # (B, T, F) - original format\n",
    "            x = x.unsqueeze(1)  # (B, 1, T, F)\n",
    "            x = x.transpose(2, 3)  # (B, 1, F, T)\n",
    "        \n",
    "        # Now x is (B, 1, F, T)\n",
    "        x = self.forward_features(x) # (B, Embedding_dim)\n",
    "\n",
    "        if self.mlp_head is not None:\n",
    "            x = self.mlp_head(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def freeze_backbone(self, until_block=None):\n",
    "        \"\"\"\n",
    "        Freeze transformer blocks for fine-tuning.\n",
    "        :param until_block: freeze blocks up to and including this index (None = freeze all)\n",
    "        \"\"\"\n",
    "        # Freeze patch embedding\n",
    "        for p in self.v.patch_embed.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "        # Freeze positional embeddings\n",
    "        self.v.pos_embed.requires_grad = False\n",
    "        self.v.cls_token.requires_grad = False\n",
    "        self.v.dist_token.requires_grad = False\n",
    "        \n",
    "        # Freeze transformer blocks\n",
    "        for i, blk in enumerate(self.v.blocks):\n",
    "            if until_block is None or i <= until_block:\n",
    "                for p in blk.parameters():\n",
    "                    p.requires_grad = False\n",
    "\n",
    "    def unfreeze_all(self):\n",
    "        \"\"\"Unfreeze all parameters.\"\"\"\n",
    "        for p in self.parameters():\n",
    "            p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "495a321c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------AST Model Summary---------------\n",
      "ImageNet pretraining: True, AudioSet pretraining: True\n",
      "Loading AudioSet pretrained model from /Users/gkont/Documents/Code/pretrained_models/audioset_10_10_0.4593.pth\n",
      "No mismatch for key: v.cls_token\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.pos_embed\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.dist_token\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.patch_embed.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.patch_embed.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.norm.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.norm.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.head.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.head.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.head_dist.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.head_dist.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: mlp_head.0.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: mlp_head.0.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: mlp_head.1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: mlp_head.1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "Loaded 155/155 tensors from AudioSet checkpoint\n",
      "The remaining 0 tensors are randomly initialized and will be trained from scratch.\n",
      "frequency stride=10, time stride=10\n",
      "number of patches=1212\n",
      "Images size after patch embedding: torch.Size([2, 1212, 768])\n",
      "CLS token shape: torch.Size([1, 1, 768])\n",
      "Expanded CLS token shape: torch.Size([2, 1, 768])\n",
      "Expanded distillation token shape: torch.Size([2, 1, 768])\n",
      "Shape after concatenating tokens: torch.Size([2, 1214, 768])\n",
      "Positional embedding shape: torch.Size([1, 1214, 768])\n",
      "torch.Size([2, 1214, 768])\n",
      "x.shape after blocks: torch.Size([2, 1214, 768])\n",
      "x.shape after norm: torch.Size([2, 1214, 768])\n",
      "x.shape after averaging tokens: torch.Size([2, 768])\n",
      "torch.Size([2, 768])\n"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.randn(2, 1, 128, 1024).to(DEVICE)\n",
    "model = ASTModel(\n",
    "    label_dim=2,\n",
    "    fstride=10,\n",
    "    tstride=10,\n",
    "    input_fdim=128,\n",
    "    input_tdim=1024,\n",
    "    imagenet_pretrain=True,\n",
    "    audioset_pretrain=True,\n",
    "    audioset_ckpt_path='/Users/gkont/Documents/Code/pretrained_models/audioset_10_10_0.4593.pth',\n",
    "    model_size='base384',\n",
    "    verbose=True,\n",
    "    backbone_only=True,\n",
    "    dropout_p=0.3,\n",
    ").to(DEVICE)\n",
    "output = model(dummy_input)\n",
    "print(output.shape)  # torch.Size([2, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db561332",
   "metadata": {},
   "source": [
    "## Baseline, Naive Concatenation & Projection Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62a656bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASTBaseline(nn.Module):\n",
    "    \"\"\"\n",
    "    Baseline: AST encoder -> MLP -> 2 logits (crackle, wheeze).\n",
    "    Matches Section 2.1 (Baseline Model) in your Methods.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        ast_kwargs: dict,\n",
    "        hidden_dim: int = 64,\n",
    "        dropout_p: float = 0.3,\n",
    "        num_labels: int = 2,      # crackle, wheeze\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # AST as backbone-only encoder (returns h_CLS)\n",
    "        self.ast = ASTModel(\n",
    "            backbone_only=True,\n",
    "            **ast_kwargs\n",
    "        )\n",
    "        print(self.ast)\n",
    "        D = self.ast.original_embedding_dim\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(D),\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(D, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(hidden_dim, num_labels)   # logits (no sigmoid)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (B, T, F) or (B, 1, F, T)\n",
    "        returns: (B, 2) logits (crackle, wheeze)\n",
    "        \"\"\"\n",
    "        h_cls = self.ast(x)           # (B, D), your h_CLS\n",
    "        print(f\"h_cls shape: {h_cls.shape}\")  # (B, D)\n",
    "        logits = self.classifier(h_cls)\n",
    "        print(f\"logits shape: {logits.shape}\")  # (B, 2)\n",
    "        return logits\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "870d0722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------AST Model Summary---------------\n",
      "ImageNet pretraining: True, AudioSet pretraining: True\n",
      "Loading AudioSet pretrained model from /Users/gkont/Documents/Code/pretrained_models/audioset_10_10_0.4593.pth\n",
      "No mismatch for key: v.cls_token\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.pos_embed\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.dist_token\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.patch_embed.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.patch_embed.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.norm.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.norm.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.head.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.head.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.head_dist.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.head_dist.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: mlp_head.0.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: mlp_head.0.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: mlp_head.1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: mlp_head.1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "Loaded 155/155 tensors from AudioSet checkpoint\n",
      "The remaining 0 tensors are randomly initialized and will be trained from scratch.\n",
      "frequency stride=10, time stride=10\n",
      "number of patches=1212\n",
      "ASTModel(\n",
      "  (reg_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (v): DistilledVisionTransformer(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10))\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "    (blocks): ModuleList(\n",
      "      (0-11): 12 x Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (pre_logits): Identity()\n",
      "    (head): Linear(in_features=768, out_features=1000, bias=True)\n",
      "    (head_dist): Linear(in_features=768, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "ast_kwargs = dict(\n",
    "    label_dim=2,          # unused since backbone_only=True\n",
    "    fstride=10,\n",
    "    tstride=10,\n",
    "    input_fdim=128,\n",
    "    input_tdim=1024,\n",
    "    imagenet_pretrain=True,\n",
    "    audioset_pretrain=True,\n",
    "    audioset_ckpt_path='/Users/gkont/Documents/Code/pretrained_models/audioset_10_10_0.4593.pth',\n",
    "    model_size='base384',\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "baseline_model = ASTBaseline(ast_kwargs, hidden_dim=64, dropout_p=0.3, num_labels=2).to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3f67403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images size after patch embedding: torch.Size([2, 1212, 768])\n",
      "CLS token shape: torch.Size([1, 1, 768])\n",
      "Expanded CLS token shape: torch.Size([2, 1, 768])\n",
      "Expanded distillation token shape: torch.Size([2, 1, 768])\n",
      "Shape after concatenating tokens: torch.Size([2, 1214, 768])\n",
      "Positional embedding shape: torch.Size([1, 1214, 768])\n",
      "torch.Size([2, 1214, 768])\n",
      "x.shape after blocks: torch.Size([2, 1214, 768])\n",
      "x.shape after norm: torch.Size([2, 1214, 768])\n",
      "x.shape after averaging tokens: torch.Size([2, 768])\n",
      "h_cls shape: torch.Size([2, 768])\n",
      "logits shape: torch.Size([2, 2])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "out = baseline_model(dummy_input)  # (2, 2)\n",
    "print(out.shape)  # torch.Size([2, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2a3b76",
   "metadata": {},
   "source": [
    "## class ASTWithNaiveMetadataConcat(nn.Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d00f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASTWithNaiveMetadataConcat(nn.Module):\n",
    "    \"\"\"\n",
    "    Early fusion: [h_CLS; m] -> MLP -> 2 logits.\n",
    "\n",
    "    m is assumed to be a normalized, preprocessed metadata vector\n",
    "    (e.g. z-scored continuous + one-hot categorical).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        ast_kwargs: dict,\n",
    "        metadata_dim: int,\n",
    "        hidden_dim: int = 128,\n",
    "        dropout_p: float = 0.3,\n",
    "        num_labels: int = 2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.ast = ASTModel(\n",
    "            backbone_only=True,\n",
    "            **ast_kwargs\n",
    "        )\n",
    "        D = self.ast.original_embedding_dim\n",
    "        self.metadata_dim = metadata_dim\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(D + metadata_dim),\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(D + metadata_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(hidden_dim, num_labels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, m):\n",
    "        \"\"\"\n",
    "        x: (B, T, F) or (B, 1, F, T)\n",
    "        m: (B, M) metadata vector\n",
    "        \"\"\"\n",
    "        h_cls = self.ast(x)              # (B, D)\n",
    "        z = torch.cat([h_cls, m], dim=-1)  # (B, D+M)\n",
    "        logits = self.classifier(z)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5185d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "astnaive = ASTWithNaiveMetadataConcat(ast_kwargs, metadata_dim=10, hidden_dim=64, dropout_p=0.3, num_labels=2).to(DEVICE)\n",
    "print(astnaive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999c1af4",
   "metadata": {},
   "source": [
    "### Projected added metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4981fae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASTWithMetadataProjection(nn.Module):\n",
    "    \"\"\"\n",
    "    Metadata projection fusion:\n",
    "        m -> m' in R^D\n",
    "        h_tilde = h_CLS + m'\n",
    "        h_tilde -> MLP -> logits\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        ast_kwargs: dict,\n",
    "        metadata_dim: int,\n",
    "        hidden_dim: int = 64,\n",
    "        dropout_p: float = 0.3,\n",
    "        num_labels: int = 2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.ast = ASTModel(\n",
    "            backbone_only=True,\n",
    "            **ast_kwargs\n",
    "        )\n",
    "        D = self.ast.original_embedding_dim\n",
    "        self.metadata_dim = metadata_dim\n",
    "\n",
    "        # Linear projection m -> m' in R^D\n",
    "        self.metadata_proj = nn.Linear(metadata_dim, D)\n",
    "\n",
    "        # Same style classifier as baseline\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(D),\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(D, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(hidden_dim, num_labels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, m):\n",
    "        \"\"\"\n",
    "        x: (B, T, F) or (B, 1, F, T)\n",
    "        m: (B, M)\n",
    "        \"\"\"\n",
    "        h_cls = self.ast(x)               # (B, D)\n",
    "        m_prime = self.metadata_proj(m)   # (B, D)\n",
    "        h_tilde = h_cls + m_prime         # (B, D)  -- Eq. (11)\n",
    "        logits = self.classifier(h_tilde)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f8874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "astproj = ASTWithMetadataProjection(ast_kwargs, metadata_dim=10, hidden_dim=64, dropout_p=0.3, num_labels=2).to(DEVICE)\n",
    "print(astproj)\n",
    "out = astproj(dummy_input, metadata)  # (2, 2)\n",
    "print(out.shape)  # torch.Size([2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbab1d89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0827f6d",
   "metadata": {},
   "source": [
    "### FiLM: Metadata conditioning inside the Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c60cef42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASTFiLM(ASTModel):\n",
    "    \"\"\"\n",
    "    AST with FiLM conditioning on selected Transformer layers.\n",
    "\n",
    "    - Uses ASTModel's __init__ to build the DeiT backbone.\n",
    "    - Adds a metadata encoder g(m).\n",
    "    - For a set of layers B, generates layer-specific gamma_l, beta_l.\n",
    "    - Applies FiLM after the MHSA residual, before the FFN (as per your equations).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        metadata_dim: int,\n",
    "        conditioned_layers=(0, 1, 2, 3),   # indices into self.v.blocks\n",
    "        metadata_hidden_dim: int = 64,\n",
    "        film_hidden_dim: int = 64,\n",
    "        num_labels: int = 2,\n",
    "        dropout_p: float = 0.3,\n",
    "        ast_kwargs: dict = None,\n",
    "    ):\n",
    "        ast_kwargs = ast_kwargs or {}\n",
    "        super().__init__(backbone_only=True, **ast_kwargs)\n",
    "\n",
    "        self.metadata_dim = metadata_dim\n",
    "        self.conditioned_layers = sorted(list(conditioned_layers))\n",
    "        self.conditioned_layers_set = set(self.conditioned_layers)\n",
    "\n",
    "        D = self.original_embedding_dim\n",
    "        self.num_layers = len(self.v.blocks)\n",
    "\n",
    "        # Metadata encoder h_m = g(m)\n",
    "        self.metadata_encoder = nn.Sequential(\n",
    "            nn.LayerNorm(metadata_dim),\n",
    "            nn.Linear(metadata_dim, metadata_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(metadata_hidden_dim, film_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # One FiLM generator per conditioned layer:\n",
    "        # f_l: h_m -> [gamma_l || beta_l] in R^{2D}\n",
    "        self.film_generators = nn.ModuleDict()\n",
    "        for l in self.conditioned_layers:\n",
    "            self.film_generators[str(l)] = nn.Linear(film_hidden_dim, 2 * D)\n",
    "\n",
    "        # Classification head (same as baseline)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(D),\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(D, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(64, num_labels)\n",
    "        )\n",
    "\n",
    "    def forward_features(self, x, m):\n",
    "        \"\"\"\n",
    "        x: (B, 1, F, T)  (we'll handle 3D in forward())\n",
    "        m: (B, M) metadata\n",
    "        returns: h_CLS in R^D (FiLM-conditioned)\n",
    "        \"\"\"\n",
    "        B = x.shape[0]\n",
    "\n",
    "        # Patch embedding: (B, N, D)\n",
    "        x = self.v.patch_embed(x)\n",
    "\n",
    "        # CLS + dist tokens and positional embeddings\n",
    "        cls_tokens = self.v.cls_token.expand(B, -1, -1)\n",
    "        dist_token = self.v.dist_token.expand(B, -1, -1)\n",
    "        x = torch.cat((cls_tokens, dist_token, x), dim=1)\n",
    "        x = x + self.v.pos_embed\n",
    "        x = self.v.pos_drop(x)\n",
    "\n",
    "        # Encode metadata once, then generate FiLM params per layer\n",
    "        h_m = self.metadata_encoder(m)   # (B, film_hidden_dim)\n",
    "\n",
    "        gamma = {}\n",
    "        beta = {}\n",
    "        for l in self.conditioned_layers:\n",
    "            film = self.film_generators[str(l)](h_m)  # (B, 2D)\n",
    "            g_l, b_l = film.chunk(2, dim=-1)          # (B, D), (B, D)\n",
    "            gamma[l] = g_l\n",
    "            beta[l] = b_l\n",
    "\n",
    "        # Manually unroll each Transformer block\n",
    "        for layer_idx, blk in enumerate(self.v.blocks):\n",
    "            # MHSA sublayer with pre-norm\n",
    "            attn_out = blk.attn(blk.norm1(x))\n",
    "            x = x + blk.drop_path(attn_out)   # Z_tilde_l\n",
    "\n",
    "            # Apply FiLM after MHSA for selected layers\n",
    "            if layer_idx in self.conditioned_layers_set:\n",
    "                print(f\"Applying FiLM at layer {layer_idx}\")\n",
    "                g_l = gamma[layer_idx].unsqueeze(1)   # (B, 1, D) -> broadcast over tokens\n",
    "                b_l = beta[layer_idx].unsqueeze(1)    # (B, 1, D)\n",
    "                x = g_l * x + b_l                     # Eq. (1415): hat{Z}_l\n",
    "\n",
    "            # FFN + residual\n",
    "            x = x + blk.drop_path(blk.mlp(blk.norm2(x)))\n",
    "\n",
    "        x = self.v.norm(x)\n",
    "        h_cls = (x[:, 0] + x[:, 1]) / 2  # pooled token\n",
    "        return h_cls\n",
    "\n",
    "    def forward(self, x, m):\n",
    "        \"\"\"\n",
    "        x: (B, T, F) or (B, 1, F, T)\n",
    "        m: (B, M) metadata\n",
    "        \"\"\"\n",
    "        if x.dim() == 3:\n",
    "            x = x.unsqueeze(1).transpose(2, 3)  # (B, 1, F, T)\n",
    "\n",
    "        h_cls = self.forward_features(x, m)\n",
    "        logits = self.classifier(h_cls)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03d2a5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------AST Model Summary---------------\n",
      "ImageNet pretraining: True, AudioSet pretraining: True\n",
      "Loading AudioSet pretrained model from /Users/gkont/Documents/Code/pretrained_models/audioset_10_10_0.4593.pth\n",
      "No mismatch for key: v.cls_token\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.pos_embed\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.dist_token\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.patch_embed.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.patch_embed.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.norm.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.norm.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.head.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.head.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.head_dist.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.head_dist.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: mlp_head.0.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: mlp_head.0.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: mlp_head.1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: mlp_head.1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "Loaded 155/155 tensors from AudioSet checkpoint\n",
      "The remaining 0 tensors are randomly initialized and will be trained from scratch.\n",
      "frequency stride=10, time stride=10\n",
      "number of patches=1212\n",
      "ASTFiLM(\n",
      "  (reg_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (v): DistilledVisionTransformer(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10))\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "    (blocks): ModuleList(\n",
      "      (0-11): 12 x Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (pre_logits): Identity()\n",
      "    (head): Linear(in_features=768, out_features=1000, bias=True)\n",
      "    (head_dist): Linear(in_features=768, out_features=1000, bias=True)\n",
      "  )\n",
      "  (metadata_encoder): Sequential(\n",
      "    (0): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Linear(in_features=10, out_features=64, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (4): ReLU()\n",
      "  )\n",
      "  (film_generators): ModuleDict(\n",
      "    (0): Linear(in_features=64, out_features=1536, bias=True)\n",
      "    (1): Linear(in_features=64, out_features=1536, bias=True)\n",
      "    (2): Linear(in_features=64, out_features=1536, bias=True)\n",
      "    (3): Linear(in_features=64, out_features=1536, bias=True)\n",
      "    (4): Linear(in_features=64, out_features=1536, bias=True)\n",
      "    (5): Linear(in_features=64, out_features=1536, bias=True)\n",
      "    (6): Linear(in_features=64, out_features=1536, bias=True)\n",
      "    (7): Linear(in_features=64, out_features=1536, bias=True)\n",
      "    (8): Linear(in_features=64, out_features=1536, bias=True)\n",
      "    (9): Linear(in_features=64, out_features=1536, bias=True)\n",
      "    (10): Linear(in_features=64, out_features=1536, bias=True)\n",
      "    (11): Linear(in_features=64, out_features=1536, bias=True)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Dropout(p=0.3, inplace=False)\n",
      "    (2): Linear(in_features=768, out_features=64, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Dropout(p=0.3, inplace=False)\n",
      "    (5): Linear(in_features=64, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "Applying FiLM at layer 0\n",
      "Applying FiLM at layer 1\n",
      "Applying FiLM at layer 2\n",
      "Applying FiLM at layer 3\n",
      "Applying FiLM at layer 4\n",
      "Applying FiLM at layer 5\n",
      "Applying FiLM at layer 6\n",
      "Applying FiLM at layer 7\n",
      "Applying FiLM at layer 8\n",
      "Applying FiLM at layer 9\n",
      "Applying FiLM at layer 10\n",
      "Applying FiLM at layer 11\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "astfilm = ASTFiLM(\n",
    "    ast_kwargs=ast_kwargs, \n",
    "    metadata_dim=10,\n",
    "    conditioned_layers=range(12), # all layers\n",
    "    metadata_hidden_dim=64, \n",
    "    film_hidden_dim=64,\n",
    "    dropout_p=0.3, \n",
    "    num_labels=2\n",
    ").to(DEVICE)\n",
    "print(astfilm)\n",
    "metadata  = torch.randn(2, 10).to(DEVICE)  # (B, M)\n",
    "out = astfilm(dummy_input, metadata)  # (2, 2)\n",
    "print(out.shape)  # torch.Size([2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad639488",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASTFiLMPlusPlus(ASTModel):\n",
    "    \"\"\"\n",
    "    FiLM++: factor-aligned grouped FiLM with K=3 groups:\n",
    "      - device group    (D_dev)\n",
    "      - site group      (D_site)\n",
    "      - rest group      (D_rest)\n",
    "\n",
    "    Metadata inputs are passed separately as (m_dev, m_site, m_rest).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        dev_metadata_dim: int,\n",
    "        site_metadata_dim: int,\n",
    "        rest_metadata_dim: int,\n",
    "        D_dev: int,\n",
    "        D_site: int,\n",
    "        conditioned_layers=(0, 1, 2, 3),\n",
    "        metadata_hidden_dim: int = 64,\n",
    "        film_hidden_dim: int = 64,\n",
    "        num_labels: int = 2,\n",
    "        dropout_p: float = 0.3,\n",
    "        ast_kwargs: dict = None,\n",
    "    ):\n",
    "        ast_kwargs = ast_kwargs or {}\n",
    "        super().__init__(backbone_only=True, **ast_kwargs)\n",
    "\n",
    "        self.conditioned_layers = sorted(list(conditioned_layers))\n",
    "        self.conditioned_layers_set = set(self.conditioned_layers)\n",
    "\n",
    "        D_total = self.original_embedding_dim\n",
    "        assert D_dev + D_site <= D_total, \"D_dev + D_site must be <= total embedding dim\"\n",
    "        D_rest = D_total - D_dev - D_site\n",
    "\n",
    "        self.D_dev = D_dev\n",
    "        self.D_site = D_site\n",
    "        self.D_rest = D_rest\n",
    "        self.D_total = D_total\n",
    "\n",
    "        # --- Metadata encoders for each factor ---\n",
    "        self.dev_encoder = nn.Sequential(\n",
    "            nn.LayerNorm(dev_metadata_dim),\n",
    "            nn.Linear(dev_metadata_dim, metadata_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(metadata_hidden_dim, film_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.site_encoder = nn.Sequential(\n",
    "            nn.LayerNorm(site_metadata_dim),\n",
    "            nn.Linear(site_metadata_dim, metadata_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(metadata_hidden_dim, film_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.rest_encoder = nn.Sequential(\n",
    "            nn.LayerNorm(rest_metadata_dim),\n",
    "            nn.Linear(rest_metadata_dim, metadata_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(metadata_hidden_dim, film_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # --- FiLM generators per group and per conditioned layer ---\n",
    "        self.dev_film = nn.ModuleDict()\n",
    "        self.site_film = nn.ModuleDict()\n",
    "        self.rest_film = nn.ModuleDict()\n",
    "        for l in self.conditioned_layers:\n",
    "            self.dev_film[str(l)] = nn.Linear(film_hidden_dim, 2 * D_dev)\n",
    "            self.site_film[str(l)] = nn.Linear(film_hidden_dim, 2 * D_site)\n",
    "            self.rest_film[str(l)] = nn.Linear(film_hidden_dim, 2 * D_rest)\n",
    "\n",
    "        # Classification head (same style as baseline)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(D_total),\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(D_total, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(64, num_labels),\n",
    "        )\n",
    "\n",
    "    def _apply_filmpp_grouped(self, x, gammas, betas):\n",
    "        \"\"\"\n",
    "        x:      (B, T, D_total)\n",
    "        gammas: dict with 'dev','site','rest' tensors (B, D_group)\n",
    "        betas:  same as above\n",
    "\n",
    "        Applies group-wise FiLM and returns (B, T, D_total).\n",
    "        \"\"\"\n",
    "        B, T, D = x.shape\n",
    "        D_dev, D_site, D_rest = self.D_dev, self.D_site, self.D_rest\n",
    "\n",
    "        x_dev, x_site, x_rest = torch.split(\n",
    "            x, [D_dev, D_site, D_rest], dim=-1\n",
    "        )  # each (B, T, D_group)\n",
    "\n",
    "        # Broadcast gammas/betas over tokens\n",
    "        g_dev = gammas[\"dev\"].unsqueeze(1)   # (B, 1, D_dev)\n",
    "        b_dev = betas[\"dev\"].unsqueeze(1)\n",
    "        g_site = gammas[\"site\"].unsqueeze(1) # (B, 1, D_site)\n",
    "        b_site = betas[\"site\"].unsqueeze(1)\n",
    "        g_rest = gammas[\"rest\"].unsqueeze(1) # (B, 1, D_rest)\n",
    "        b_rest = betas[\"rest\"].unsqueeze(1)\n",
    "\n",
    "        x_dev_hat = g_dev * x_dev + b_dev\n",
    "        x_site_hat = g_site * x_site + b_site\n",
    "        x_rest_hat = g_rest * x_rest + b_rest\n",
    "\n",
    "        x_hat = torch.cat([x_dev_hat, x_site_hat, x_rest_hat], dim=-1)  # (B, T, D_total)\n",
    "        return x_hat\n",
    "\n",
    "    def forward_features(self, x, m_dev, m_site, m_rest):\n",
    "        \"\"\"\n",
    "        x:      (B, 1, F, T)\n",
    "        m_dev:  (B, dev_metadata_dim)\n",
    "        m_site: (B, site_metadata_dim)\n",
    "        m_rest: (B, rest_metadata_dim)\n",
    "        \"\"\"\n",
    "        B = x.shape[0]\n",
    "\n",
    "        # Patch embedding\n",
    "        x = self.v.patch_embed(x)\n",
    "        cls_tokens = self.v.cls_token.expand(B, -1, -1)\n",
    "        dist_token = self.v.dist_token.expand(B, -1, -1)\n",
    "        x = torch.cat((cls_tokens, dist_token, x), dim=1)\n",
    "        x = x + self.v.pos_embed\n",
    "        x = self.v.pos_drop(x)\n",
    "\n",
    "        # Encode metadata for each factor\n",
    "        h_dev = self.dev_encoder(m_dev)\n",
    "        h_site = self.site_encoder(m_site)\n",
    "        h_rest = self.rest_encoder(m_rest)\n",
    "\n",
    "        # Precompute gamma,beta for each conditioned layer\n",
    "        gamma_dev, beta_dev = {}, {}\n",
    "        gamma_site, beta_site = {}, {}\n",
    "        gamma_rest, beta_rest = {}, {}\n",
    "\n",
    "        for l in self.conditioned_layers:\n",
    "            dev_params = self.dev_film[str(l)](h_dev)   # (B, 2*D_dev)\n",
    "            site_params = self.site_film[str(l)](h_site) # (B, 2*D_site)\n",
    "            rest_params = self.rest_film[str(l)](h_rest) # (B, 2*D_rest)\n",
    "\n",
    "            g_dev, b_dev = dev_params.chunk(2, dim=-1)\n",
    "            g_site, b_site = site_params.chunk(2, dim=-1)\n",
    "            g_rest, b_rest = rest_params.chunk(2, dim=-1)\n",
    "\n",
    "            gamma_dev[l], beta_dev[l] = g_dev, b_dev\n",
    "            gamma_site[l], beta_site[l] = g_site, b_site\n",
    "            gamma_rest[l], beta_rest[l] = g_rest, b_rest\n",
    "\n",
    "        # Unroll ViT blocks with FiLM++ after MHSA\n",
    "        for layer_idx, blk in enumerate(self.v.blocks):\n",
    "            attn_out = blk.attn(blk.norm1(x))\n",
    "            x = x + blk.drop_path(attn_out)   # (B, T, D_total)\n",
    "\n",
    "            if layer_idx in self.conditioned_layers_set:\n",
    "                gammas = {\n",
    "                    \"dev\": gamma_dev[layer_idx],\n",
    "                    \"site\": gamma_site[layer_idx],\n",
    "                    \"rest\": gamma_rest[layer_idx],\n",
    "                }\n",
    "                betas = {\n",
    "                    \"dev\": beta_dev[layer_idx],\n",
    "                    \"site\": beta_site[layer_idx],\n",
    "                    \"rest\": beta_rest[layer_idx],\n",
    "                }\n",
    "                x = self._apply_filmpp_grouped(x, gammas, betas)\n",
    "\n",
    "            x = x + blk.drop_path(blk.mlp(blk.norm2(x)))\n",
    "\n",
    "        x = self.v.norm(x)\n",
    "        h_cls = (x[:, 0] + x[:, 1]) / 2\n",
    "        return h_cls\n",
    "\n",
    "    def forward(self, x, m_dev, m_site, m_rest):\n",
    "        \"\"\"\n",
    "        x:      (B, T, F) or (B, 1, F, T)\n",
    "        m_dev:  (B, dev_metadata_dim)\n",
    "        m_site: (B, site_metadata_dim)\n",
    "        m_rest: (B, rest_metadata_dim)\n",
    "        \"\"\"\n",
    "        if x.dim() == 3:\n",
    "            x = x.unsqueeze(1).transpose(2, 3)\n",
    "\n",
    "        h_cls = self.forward_features(x, m_dev, m_site, m_rest)\n",
    "        logits = self.classifier(h_cls)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c50fbd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------AST Model Summary---------------\n",
      "ImageNet pretraining: True, AudioSet pretraining: True\n",
      "Loading AudioSet pretrained model from /Users/gkont/Documents/Code/pretrained_models/audioset_10_10_0.4593.pth\n",
      "No mismatch for key: v.cls_token\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.pos_embed\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.dist_token\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.patch_embed.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.patch_embed.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.0.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.1.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.2.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.3.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.4.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.5.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.6.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.7.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.8.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.9.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.10.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.norm1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.norm1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.attn.qkv.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.attn.qkv.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.attn.proj.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.attn.proj.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.norm2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.norm2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.mlp.fc1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.mlp.fc1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.mlp.fc2.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.blocks.11.mlp.fc2.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.norm.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.norm.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.head.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.head.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.head_dist.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: v.head_dist.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: mlp_head.0.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: mlp_head.0.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: mlp_head.1.weight\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "No mismatch for key: mlp_head.1.bias\n",
      "No mlp_head weights loaded from AudioSet checkpoint.\n",
      "Loaded 155/155 tensors from AudioSet checkpoint\n",
      "The remaining 0 tensors are randomly initialized and will be trained from scratch.\n",
      "frequency stride=10, time stride=10\n",
      "number of patches=1212\n",
      "ASTFiLMPlusPlus(\n",
      "  (reg_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (v): DistilledVisionTransformer(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10))\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "    (blocks): ModuleList(\n",
      "      (0-11): 12 x Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (pre_logits): Identity()\n",
      "    (head): Linear(in_features=768, out_features=1000, bias=True)\n",
      "    (head_dist): Linear(in_features=768, out_features=1000, bias=True)\n",
      "  )\n",
      "  (dev_encoder): Sequential(\n",
      "    (0): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Linear(in_features=4, out_features=64, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (4): ReLU()\n",
      "  )\n",
      "  (site_encoder): Sequential(\n",
      "    (0): LayerNorm((7,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Linear(in_features=7, out_features=64, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (4): ReLU()\n",
      "  )\n",
      "  (rest_encoder): Sequential(\n",
      "    (0): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Linear(in_features=3, out_features=64, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (4): ReLU()\n",
      "  )\n",
      "  (dev_film): ModuleDict(\n",
      "    (10): Linear(in_features=64, out_features=256, bias=True)\n",
      "    (11): Linear(in_features=64, out_features=256, bias=True)\n",
      "    (12): Linear(in_features=64, out_features=256, bias=True)\n",
      "  )\n",
      "  (site_film): ModuleDict(\n",
      "    (10): Linear(in_features=64, out_features=256, bias=True)\n",
      "    (11): Linear(in_features=64, out_features=256, bias=True)\n",
      "    (12): Linear(in_features=64, out_features=256, bias=True)\n",
      "  )\n",
      "  (rest_film): ModuleDict(\n",
      "    (10): Linear(in_features=64, out_features=1024, bias=True)\n",
      "    (11): Linear(in_features=64, out_features=1024, bias=True)\n",
      "    (12): Linear(in_features=64, out_features=1024, bias=True)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): Dropout(p=0.3, inplace=False)\n",
      "    (2): Linear(in_features=768, out_features=64, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Dropout(p=0.3, inplace=False)\n",
      "    (5): Linear(in_features=64, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "astfilmpp = ASTFiLMPlusPlus(\n",
    "    dev_metadata_dim=4,\n",
    "    site_metadata_dim=7,\n",
    "    rest_metadata_dim=3,\n",
    "    D_dev=128,\n",
    "    D_site=128,\n",
    "    ast_kwargs=ast_kwargs,\n",
    "    conditioned_layers=(10, 11, 12), # last 3 layers\n",
    "    metadata_hidden_dim=64, \n",
    "    film_hidden_dim=64,\n",
    "    dropout_p=0.3, \n",
    "    num_labels=2\n",
    ").to(DEVICE)\n",
    "print(astfilmpp)\n",
    "\n",
    "dev_metadata = torch.randn(2, 4).to(DEVICE)\n",
    "site_metadata = torch.randn(2, 7).to(DEVICE)\n",
    "rest_metadata = torch.randn(2, 3).to(DEVICE)\n",
    "out = astfilmpp(dummy_input, dev_metadata, site_metadata, rest_metadata)  # (2, 2)\n",
    "print(out.shape)  # torch.Size([2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740224d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icbhi-ast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
