{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d49a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b666169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ls.config.loader import load_config\n",
    "import IPython.display as ipd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2f6000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. load config ---\n",
    "cfg = load_config(\"../configs/config.yaml\")\n",
    "\n",
    "print(\"Dataset config:\", cfg.dataset)\n",
    "print(\"Audio config:\", cfg.audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384ddf89",
   "metadata": {},
   "source": [
    "## Test DataLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d58543b",
   "metadata": {},
   "source": [
    "### ICBHI Dataloader using only test set as the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbb78b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Regular training\n",
    "from ls.data.dataloaders import build_dataloaders\n",
    "\n",
    "train_loader, test_loader = build_dataloaders(cfg.dataset, cfg.audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfe5ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch[\"input_values\"].shape, batch[\"labels\"].shape, batch[\"filename\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8c27a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def inspect_batch_balance(train_loader, n_batches=100):\n",
    "    pattern_counter = Counter()\n",
    "    total = 0\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        labels = batch[\"labels\"].cpu().numpy()\n",
    "        # For multi-label mode (2 columns)\n",
    "        if labels.ndim == 2:\n",
    "            patterns = [tuple(v) for v in labels]\n",
    "        else:\n",
    "            patterns = [int(v) for v in labels]\n",
    "        pattern_counter.update(patterns)\n",
    "        total += len(patterns)\n",
    "        if i >= n_batches:\n",
    "            break\n",
    "\n",
    "    print(f\"\\nChecked {total} samples from {n_batches} batches\")\n",
    "    for pat, c in sorted(pattern_counter.items()):\n",
    "        print(f\"Pattern {pat}: {c} ({100*c/total:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab99993",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_batch_balance(train_loader, n_batches=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a391b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensors_equal(a, b, atol=1e-6, rtol=1e-5):\n",
    "    return torch.allclose(a, b, atol=atol, rtol=rtol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d036e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inspect one sample ---\n",
    "idx = torch.randint(cfg.dataset.batch_size, (1,)).item()\n",
    "print(f\"Inspecting sample index {idx} in the batch\")\n",
    "print(\"Keys:\", batch.keys())\n",
    "print(\"Filename:\", batch[\"filename\"][idx])\n",
    "print(\"Cycle index:\", batch[\"cycle_index\"][idx])\n",
    "print(\"Label:\", batch[\"labels\"][idx])\n",
    "print(\"Duration:\", batch[\"duration\"][idx])\n",
    "print(\"Start-End:\", batch[\"start_time\"][idx], \"-\", batch[\"end_time\"][idx])\n",
    "print(\"Crackle/Wheeze:\", batch[\"crackle\"][idx], batch[\"wheeze\"][idx])\n",
    "# print(sample[\"aug_audio\"].shape, sample[\"aug_fbank\"].shape, sample[\"audio\"].shape, sample[\"fbank\"].shape)\n",
    "print(\"Waveform shape:\", batch[\"audio\"][idx].shape)\n",
    "print(\"Mel image shape:\", batch[\"input_values\"][idx].shape)\n",
    "# print(f\"Waveform augmented: {not tensors_equal(batch['audio'][idx].view(-1), batch['aug_audio'][idx].view(-1))}\")\n",
    "# print(f\"Mel augmented: {not tensors_equal(batch['fbank'][idx].view(-1), batch['aug_fbank'][idx].view(-1))}\")\n",
    "\n",
    "# --- 4. Plot waveform ---\n",
    "waveform = batch[\"audio\"][idx].squeeze().numpy()\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.plot(waveform)\n",
    "plt.title(f\"Waveform ({batch['filename'][idx]} - cycle {batch['cycle_index'][idx]})\")\n",
    "plt.show()\n",
    "\n",
    "# --- 5. Plot mel spectrogram ---\n",
    "mel = batch[\"input_values\"][idx].squeeze(0)  # [freq, time] for imshow\n",
    "freq_axis = np.linspace(0, cfg.audio.sample_rate // 2, mel.shape[0])\n",
    "time_axis = np.arange(mel.shape[1]) * cfg.audio.frame_shift / 1000  # in seconds\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.imshow(mel, origin=\"lower\", aspect=\"auto\", extent=[0, time_axis[-1], 0, freq_axis[-1]], cmap=\"viridis\")\n",
    "plt.title(\"Mel filterbank\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "ipd.Audio(waveform, rate=cfg.audio.sample_rate)  # listen to the sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b06535e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ls.data.dataloaders import compute_and_cache_stats\n",
    "\n",
    "mean, std = compute_and_cache_stats(\n",
    "    train_loader.dataset, cache_file=\"train_stats.json\", batch_size=cfg.dataset.batch_size,\n",
    "    num_workers=cfg.dataset.num_workers\n",
    ")\n",
    "print(f\"Dataset mean: {mean:.4f}, std: {std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274e1f34",
   "metadata": {},
   "source": [
    "## Stratified Grouped KFold Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83e26d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ls.data.dataloaders import build_train_val_kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149950ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or: k-fold CV on train set\n",
    "folds, test_loader = build_train_val_kfold(\n",
    "    cfg.dataset, cfg.audio, n_splits=5, max_retries=50, seed=cfg.seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f5e695",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (train_loader, val_loader) in enumerate(folds):\n",
    "    # print(f\"Training fold {i+1}\")\n",
    "    for batch in train_loader:\n",
    "        # Process each batch\n",
    "        print(batch[\"input_values\"].shape, batch[\"label\"].shape, batch[\"filename\"])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143e4bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icbhi-ast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
