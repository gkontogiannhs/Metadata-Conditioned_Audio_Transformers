{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bb6c2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cb0c0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ls.config.loader import load_config\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168c56a4",
   "metadata": {},
   "source": [
    "### Load configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df52e78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_config(\"../configs/config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a2b008a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(cfg.dataset.data_folder, \"icbhi_metadata.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60660a73",
   "metadata": {},
   "source": [
    "### Create columns for 4-class and 2-class problems and cycle duraitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0d63343",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label_4c'] = df.apply(lambda r: \n",
    "    'Crackle' if r.Crackles==1 and r.Wheezes==0 else\n",
    "    'Wheeze'  if r.Crackles==0 and r.Wheezes==1 else\n",
    "    'Both'    if r.Crackles==1 and r.Wheezes==1 else\n",
    "    'Normal', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b2a6346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>Filename</th>\n",
       "      <th>CycleIndex</th>\n",
       "      <th>CycleStart</th>\n",
       "      <th>CycleEnd</th>\n",
       "      <th>Crackles</th>\n",
       "      <th>Wheezes</th>\n",
       "      <th>Split</th>\n",
       "      <th>Device</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>BMI</th>\n",
       "      <th>CW</th>\n",
       "      <th>CH</th>\n",
       "      <th>Disease</th>\n",
       "      <th>AuscLoc</th>\n",
       "      <th>label_4c</th>\n",
       "      <th>label_2c</th>\n",
       "      <th>CycleDur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>101_1b1_Al_sc_Meditron</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>Meditron</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>URTI</td>\n",
       "      <td>Al</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0.543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>101_1b1_Al_sc_Meditron</td>\n",
       "      <td>1</td>\n",
       "      <td>0.579</td>\n",
       "      <td>2.450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>Meditron</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>URTI</td>\n",
       "      <td>Al</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>1.871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>101_1b1_Al_sc_Meditron</td>\n",
       "      <td>2</td>\n",
       "      <td>2.450</td>\n",
       "      <td>3.893</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>Meditron</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>URTI</td>\n",
       "      <td>Al</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>1.443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101</td>\n",
       "      <td>101_1b1_Al_sc_Meditron</td>\n",
       "      <td>3</td>\n",
       "      <td>3.893</td>\n",
       "      <td>5.793</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>Meditron</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>URTI</td>\n",
       "      <td>Al</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>1.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101</td>\n",
       "      <td>101_1b1_Al_sc_Meditron</td>\n",
       "      <td>4</td>\n",
       "      <td>5.793</td>\n",
       "      <td>7.521</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>Meditron</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>URTI</td>\n",
       "      <td>Al</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>1.728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PID                Filename  CycleIndex  CycleStart  CycleEnd  Crackles  \\\n",
       "0  101  101_1b1_Al_sc_Meditron           0       0.036     0.579         0   \n",
       "1  101  101_1b1_Al_sc_Meditron           1       0.579     2.450         0   \n",
       "2  101  101_1b1_Al_sc_Meditron           2       2.450     3.893         0   \n",
       "3  101  101_1b1_Al_sc_Meditron           3       3.893     5.793         0   \n",
       "4  101  101_1b1_Al_sc_Meditron           4       5.793     7.521         0   \n",
       "\n",
       "   Wheezes Split    Device  Fold  Age Sex  BMI    CW    CH Disease AuscLoc  \\\n",
       "0        0  test  Meditron     1  3.0   F  NaN  19.0  99.0    URTI      Al   \n",
       "1        0  test  Meditron     1  3.0   F  NaN  19.0  99.0    URTI      Al   \n",
       "2        0  test  Meditron     1  3.0   F  NaN  19.0  99.0    URTI      Al   \n",
       "3        0  test  Meditron     1  3.0   F  NaN  19.0  99.0    URTI      Al   \n",
       "4        0  test  Meditron     1  3.0   F  NaN  19.0  99.0    URTI      Al   \n",
       "\n",
       "  label_4c label_2c  CycleDur  \n",
       "0   Normal   Normal     0.543  \n",
       "1   Normal   Normal     1.871  \n",
       "2   Normal   Normal     1.443  \n",
       "3   Normal   Normal     1.900  \n",
       "4   Normal   Normal     1.728  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label_2c\"] = np.where((df[\"Crackles\"] + df[\"Wheezes\"]) > 0, \"Abnormal\", \"Normal\")\n",
    "df['CycleDur'] = df['CycleEnd'] - df['CycleStart']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d6504a",
   "metadata": {},
   "source": [
    "### Check for patient leakage/overlap between train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45bbf0ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "A PID appears in both splits!",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Basic integrity checks\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m df[\u001b[33m\"\u001b[39m\u001b[33mPID\u001b[39m\u001b[33m\"\u001b[39m].nunique() == df.groupby(\u001b[33m\"\u001b[39m\u001b[33mPID\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[33m\"\u001b[39m\u001b[33mSplit\u001b[39m\u001b[33m\"\u001b[39m].nunique().max(), \u001b[33m\"\u001b[39m\u001b[33mA PID appears in both splits!\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAssertionError\u001b[39m: A PID appears in both splits!"
     ]
    }
   ],
   "source": [
    "# Basic integrity checks\n",
    "assert df[\"PID\"].nunique() == df.groupby(\"PID\")[\"Split\"].nunique().max(), \"A PID appears in both splits!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33870f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patients appearing in both training and test splits:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2896</th>\n",
       "      <td>156</td>\n",
       "      <td>156_2b3_Al_mc_AKGC417L</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2902</th>\n",
       "      <td>156</td>\n",
       "      <td>156_2b3_Ar_mc_AKGC417L</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2908</th>\n",
       "      <td>156</td>\n",
       "      <td>156_2b3_Ll_mc_AKGC417L</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2914</th>\n",
       "      <td>156</td>\n",
       "      <td>156_2b3_Lr_mc_AKGC417L</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2920</th>\n",
       "      <td>156</td>\n",
       "      <td>156_2b3_Pl_mc_AKGC417L</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2926</th>\n",
       "      <td>156</td>\n",
       "      <td>156_2b3_Pr_mc_AKGC417L</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2932</th>\n",
       "      <td>156</td>\n",
       "      <td>156_5b3_Al_mc_AKGC417L</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2941</th>\n",
       "      <td>156</td>\n",
       "      <td>156_5b3_Ar_mc_AKGC417L</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2950</th>\n",
       "      <td>156</td>\n",
       "      <td>156_5b3_Ll_mc_AKGC417L</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2959</th>\n",
       "      <td>156</td>\n",
       "      <td>156_5b3_Lr_mc_AKGC417L</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2968</th>\n",
       "      <td>156</td>\n",
       "      <td>156_5b3_Pl_mc_AKGC417L</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2977</th>\n",
       "      <td>156</td>\n",
       "      <td>156_5b3_Pr_mc_AKGC417L</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>156</td>\n",
       "      <td>156_8b3_Al_mc_AKGC417L</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>156</td>\n",
       "      <td>156_8b3_Ar_mc_AKGC417L</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>156</td>\n",
       "      <td>156_8b3_Ll_mc_AKGC417L</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3010</th>\n",
       "      <td>156</td>\n",
       "      <td>156_8b3_Lr_mc_AKGC417L</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3018</th>\n",
       "      <td>156</td>\n",
       "      <td>156_8b3_Pl_mc_AKGC417L</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6523</th>\n",
       "      <td>218</td>\n",
       "      <td>218_1b1_Al_sc_Meditron</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6538</th>\n",
       "      <td>218</td>\n",
       "      <td>218_1b1_Ar_sc_Meditron</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6554</th>\n",
       "      <td>218</td>\n",
       "      <td>218_1b1_Lr_sc_Meditron</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6573</th>\n",
       "      <td>218</td>\n",
       "      <td>218_1b1_Pl_sc_Meditron</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6591</th>\n",
       "      <td>218</td>\n",
       "      <td>218_1b1_Pr_sc_Meditron</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6609</th>\n",
       "      <td>218</td>\n",
       "      <td>218_1p1_Ar_sc_Litt3200</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6615</th>\n",
       "      <td>218</td>\n",
       "      <td>218_1p1_Pl_sc_Litt3200</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6623</th>\n",
       "      <td>218</td>\n",
       "      <td>218_1p1_Pr_sc_Litt3200</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PID                Filename  Split\n",
       "2896  156  156_2b3_Al_mc_AKGC417L   test\n",
       "2902  156  156_2b3_Ar_mc_AKGC417L  train\n",
       "2908  156  156_2b3_Ll_mc_AKGC417L  train\n",
       "2914  156  156_2b3_Lr_mc_AKGC417L   test\n",
       "2920  156  156_2b3_Pl_mc_AKGC417L   test\n",
       "2926  156  156_2b3_Pr_mc_AKGC417L  train\n",
       "2932  156  156_5b3_Al_mc_AKGC417L  train\n",
       "2941  156  156_5b3_Ar_mc_AKGC417L   test\n",
       "2950  156  156_5b3_Ll_mc_AKGC417L   test\n",
       "2959  156  156_5b3_Lr_mc_AKGC417L  train\n",
       "2968  156  156_5b3_Pl_mc_AKGC417L   test\n",
       "2977  156  156_5b3_Pr_mc_AKGC417L  train\n",
       "2986  156  156_8b3_Al_mc_AKGC417L   test\n",
       "2994  156  156_8b3_Ar_mc_AKGC417L  train\n",
       "3002  156  156_8b3_Ll_mc_AKGC417L  train\n",
       "3010  156  156_8b3_Lr_mc_AKGC417L   test\n",
       "3018  156  156_8b3_Pl_mc_AKGC417L  train\n",
       "6523  218  218_1b1_Al_sc_Meditron   test\n",
       "6538  218  218_1b1_Ar_sc_Meditron  train\n",
       "6554  218  218_1b1_Lr_sc_Meditron  train\n",
       "6573  218  218_1b1_Pl_sc_Meditron   test\n",
       "6591  218  218_1b1_Pr_sc_Meditron   test\n",
       "6609  218  218_1p1_Ar_sc_Litt3200  train\n",
       "6615  218  218_1p1_Pl_sc_Litt3200   test\n",
       "6623  218  218_1p1_Pr_sc_Litt3200  train"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dup_pids = (\n",
    "    df.groupby(\"PID\")[\"Split\"]\n",
    "      .nunique()\n",
    "      .reset_index()\n",
    "      .query(\"Split > 1\")\n",
    ")\n",
    "\n",
    "if not dup_pids.empty:\n",
    "    print(\"Patients appearing in both training and test splits:\")\n",
    "    display(df[df[\"PID\"].isin(dup_pids[\"PID\"])][[\"PID\",\"Filename\", \"Split\"]].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "937c6584",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (df[\"CycleDur\"] > 0).all(), \"Non-positive cycle duration found\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dff34b7",
   "metadata": {},
   "source": [
    "### Metadata Dataset Exploitation and Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8647dce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_section(title, df):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"{title.upper()}\")\n",
    "    print(\"=\"*80)\n",
    "    print(df.to_string())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf794f8a",
   "metadata": {},
   "source": [
    "## Class imbalances Calculation or the official fixed train/test split (2-class & 4-class problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b7b738",
   "metadata": {},
   "source": [
    "### Global Dataset (Train + Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f288c176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "4-CLASS GLOBAL COUNTS\n",
      "================================================================================\n",
      "          count\n",
      "label_4c       \n",
      "Normal     3642\n",
      "Crackle    1864\n",
      "Wheeze      886\n",
      "Both        506\n",
      "\n",
      "\n",
      "================================================================================\n",
      "4-CLASS GLOBAL PROPORTIONS\n",
      "================================================================================\n",
      "          proportion\n",
      "label_4c            \n",
      "Normal         0.528\n",
      "Crackle        0.270\n",
      "Wheeze         0.128\n",
      "Both           0.073\n",
      "\n",
      "\n",
      "================================================================================\n",
      "2-CLASS GLOBAL COUNTS\n",
      "================================================================================\n",
      "          count\n",
      "label_2c       \n",
      "Normal     3642\n",
      "Abnormal   3256\n",
      "\n",
      "\n",
      "================================================================================\n",
      "2-CLASS GLOBAL PROPORTIONS\n",
      "================================================================================\n",
      "          proportion\n",
      "label_2c            \n",
      "Normal         0.528\n",
      "Abnormal       0.472\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_section(\"4-Class Global Counts\", df[\"label_4c\"].value_counts().to_frame(\"count\"))\n",
    "print_section(\"4-Class Global Proportions\", df[\"label_4c\"].value_counts(normalize=True).round(3).to_frame(\"proportion\"))\n",
    "\n",
    "print_section(\"2-Class Global Counts\", df[\"label_2c\"].value_counts().to_frame(\"count\"))\n",
    "print_section(\"2-Class Global Proportions\", df[\"label_2c\"].value_counts(normalize=True).round(3).to_frame(\"proportion\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794afeb0",
   "metadata": {},
   "source": [
    "### Class imbalances for each split (4-class problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "050e77dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "4-CLASS COUNTS BY SPLIT\n",
      "================================================================================\n",
      "label_4c  Both  Crackle  Normal  Wheeze\n",
      "Split                                  \n",
      "test       143      649    1579     385\n",
      "train      363     1215    2063     501\n",
      "\n",
      "\n",
      "================================================================================\n",
      "4-CLASS PROPORTIONS BY SPLIT\n",
      "================================================================================\n",
      "label_4c   Both  Crackle  Normal  Wheeze\n",
      "Split                                   \n",
      "test      0.052    0.235   0.573   0.140\n",
      "train     0.088    0.293   0.498   0.121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# By split\n",
    "by_split_4c = df.pivot_table(index=\"Split\", columns=\"label_4c\", values=\"Filename\", aggfunc=\"count\").fillna(0).astype(int)\n",
    "by_split_prop_4c = by_split_4c.div(by_split_4c.sum(axis=1), axis=0).round(3)\n",
    "print_section(\"4-Class Counts by Split\", by_split_4c)\n",
    "print_section(\"4-Class Proportions by Split\", by_split_prop_4c)\n",
    "# print(\"\\n4c counts by Split:\\n\", by_split)\n",
    "# print(\"\\n4c proportions by Split:\\n\", by_split_prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ea6f3c",
   "metadata": {},
   "source": [
    "### Class imbalances for each split (2-class problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7849ad7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "2-CLASS COUNTS BY SPLIT\n",
      "================================================================================\n",
      "label_2c  Abnormal  Normal\n",
      "Split                     \n",
      "test          1177    1579\n",
      "train         2079    2063\n",
      "\n",
      "\n",
      "================================================================================\n",
      "2-CLASS PROPORTIONS BY SPLIT\n",
      "================================================================================\n",
      "label_2c  Abnormal  Normal\n",
      "Split                     \n",
      "test         0.427   0.573\n",
      "train        0.502   0.498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# By split\n",
    "by_split = df.pivot_table(index=\"Split\", columns=\"label_2c\", values=\"Filename\", aggfunc=\"count\").fillna(0).astype(int)\n",
    "by_split_prop = by_split.div(by_split.sum(axis=1), axis=0).round(3)\n",
    "print_section(\"2-Class Counts by Split\", by_split)\n",
    "print_section(\"2-Class Proportions by Split\", by_split_prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b8b7e2",
   "metadata": {},
   "source": [
    "### Findings:\n",
    "\n",
    "* Global 4-class: Normal 52.8%, Crackle 27.0%, Wheeze 12.8%, Both 7.3%.\n",
    "* 2-class: Normal 52.8% vs Abnormal 47.2% ‚Üí close to balanced.\n",
    "\n",
    "Train‚Äìtest label mix isn‚Äôt identical\n",
    "\n",
    "* Test has more Normal (57.3%) and fewer Crackle (23.5%) & Both (5.2%) than Train (Normal 49.8%, Crackle 29.3%, Both 8.8%).   \n",
    " -> Expect lower sensitivity on test (especially for Crackle/Both) if you tune on train-like prevalence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54aa9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "497b23d8",
   "metadata": {},
   "source": [
    "## Descriptive statistics for the breathing cycle duraiton for the 4-class problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb6bb176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CYCLE DURATION STATS (SEC) BY 4-CLASS LABEL\n",
      "================================================================================\n",
      "           count   mean    std    min    25%    50%    75%     max\n",
      "label_4c                                                          \n",
      "Both       506.0  3.060  1.092  0.571  2.238  2.904  3.558   8.592\n",
      "Crackle   1864.0  2.785  0.952  0.367  2.137  2.629  3.449   8.736\n",
      "Normal    3642.0  2.607  1.275  0.200  1.716  2.443  3.288  16.163\n",
      "Wheeze     886.0  2.703  1.143  0.228  1.803  2.584  3.357   9.217\n",
      "\n",
      "\n",
      "================================================================================\n",
      "CYCLE DURATION STATS (SEC) BY SPLIT √ó LABEL\n",
      "================================================================================\n",
      "                 count   mean    std    min    25%    50%    75%     max\n",
      "Split label_4c                                                          \n",
      "test  Both       143.0  3.358  1.316  1.057  2.277  3.233  4.007   8.592\n",
      "      Crackle    649.0  3.093  0.923  0.443  2.605  3.212  3.773   6.411\n",
      "      Normal    1579.0  2.391  1.037  0.286  1.564  2.310  3.141   7.632\n",
      "      Wheeze     385.0  2.668  1.259  0.228  1.583  2.512  3.456   9.217\n",
      "train Both       363.0  2.942  0.967  0.571  2.238  2.734  3.417   7.603\n",
      "      Crackle   1215.0  2.620  0.927  0.367  2.059  2.416  2.942   8.736\n",
      "      Normal    2063.0  2.772  1.410  0.200  1.904  2.545  3.455  16.163\n",
      "      Wheeze     501.0  2.730  1.047  0.300  2.028  2.672  3.272   7.346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dur_stats = df.groupby(\"label_4c\")[\"CycleDur\"].describe().round(3)\n",
    "# print(\"\\nCycle duration stats (sec) by 4c:\\n\", dur_stats)\n",
    "\n",
    "# per-split duration sanity\n",
    "dur_split = df.groupby([\"Split\",\"label_4c\"])[\"CycleDur\"].describe().round(3)\n",
    "# print(\"\\nCycle duration stats by Split √ó 4c:\\n\", dur_split)\n",
    "\n",
    "print_section(\"Cycle Duration Stats (sec) by 4-Class Label\", dur_stats)\n",
    "print_section(\"Cycle Duration Stats (sec) by Split √ó Label\", dur_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679743da",
   "metadata": {},
   "source": [
    "## Q1. Do breathing cycle durations differ across sound labels?\n",
    "\n",
    "H‚ÇÄ:\n",
    "\n",
    "Cycle duration distributions are identical across Normal, Crackle, Wheeze, and Both.\n",
    "\n",
    "H‚ÇÅ:\n",
    "\n",
    "At least one label‚Äôs duration distribution differs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fdede9",
   "metadata": {},
   "source": [
    "Interpretation phrasing for the paper\n",
    "\n",
    "To ensure independence across samples, we performed stratified patient-level sampling: for each sound class, one breathing cycle was randomly selected per patient exhibiting that class. This process was repeated 100 times (bootstrap resampling) to account for selection variance. Normality and variance homogeneity were violated (Shapiro‚ÄìWilk and Levene‚Äôs p<0.001), thus a Kruskal‚ÄìWallis test was applied on each bootstrap replicate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3e7d9f",
   "metadata": {},
   "source": [
    "### Goal\n",
    "\n",
    "### Quantify whether the breathing-cycle duration differs systematically between respiratory sound categories (Normal, Crackle, Wheeze, Both).\n",
    "### This assesses whether cycle duration carries discriminative information about adventitious sounds, or if it is merely random variability.\n",
    "\n",
    "* Challenges  \n",
    "\t‚Ä¢\tEach patient contributes multiple cycles ‚Üí dependent samples.  \n",
    "\t‚Ä¢\tDistributions are non-normal and heteroscedastic.  \n",
    "\t‚Ä¢\tThe dataset is imbalanced across labels.  \n",
    "\n",
    "* Approach.  \n",
    "\t1.\tPatient-wise bootstrap resampling ‚Äî one random cycle per label per patient, repeated N times, ensures approximate independence.    \n",
    "\t2.\tDistributional testing ‚Äî for each resample:   \n",
    "\t‚Ä¢\tShapiro‚ÄìWilk for normality, Levene for equal variances.   \n",
    "\t‚Ä¢\tChoose parametric (ANOVA/Welch) or non-parametric (Kruskal‚ÄìWallis).  \n",
    "\t3.\tEffect quantification ‚Äî compute Œµ¬≤ (variance explained) and, if appropriate, pairwise Mann‚ÄìWhitney tests with Cliff‚Äôs Œ¥.  \n",
    "\t4.\tStability assessment ‚Äî summarize p-values, significance fractions, and effect sizes across bootstraps.    \n",
    "\t5.\tRepeat for both label_4c (4-class) and label_2c (Normal vs Abnormal) to compare sensitivity.  \n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "484f5379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Mixed Linear Model Regression Results\n",
      "=================================================================\n",
      "Model:               MixedLM    Dependent Variable:    CycleDur  \n",
      "No. Observations:    6898       Method:                REML      \n",
      "No. Groups:          126        Scale:                 0.7533    \n",
      "Min. group size:     4          Log-Likelihood:        -9041.1718\n",
      "Max. group size:     507        Converged:             Yes       \n",
      "Mean group size:     54.7                                        \n",
      "-----------------------------------------------------------------\n",
      "                       Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "-----------------------------------------------------------------\n",
      "Intercept               3.070    0.095 32.216 0.000  2.883  3.257\n",
      "C(label_4c)[T.Crackle] -0.355    0.050 -7.084 0.000 -0.453 -0.257\n",
      "C(label_4c)[T.Normal]  -0.436    0.050 -8.717 0.000 -0.533 -0.338\n",
      "C(label_4c)[T.Wheeze]  -0.259    0.054 -4.836 0.000 -0.365 -0.154\n",
      "Group Var               0.842    0.131                           \n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "model = smf.mixedlm(\"CycleDur ~ C(label_4c)\", data=df, groups=df[\"PID\"])\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85c481b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Mixed Linear Model Regression Results\n",
      "================================================================================================\n",
      "Model:                          MixedLM              Dependent Variable:              CycleDur  \n",
      "No. Observations:               6898                 Method:                          REML      \n",
      "No. Groups:                     126                  Scale:                           0.7533    \n",
      "Min. group size:                4                    Log-Likelihood:                  -9041.1718\n",
      "Max. group size:                507                  Converged:                       Yes       \n",
      "Mean group size:                54.7                                                            \n",
      "------------------------------------------------------------------------------------------------\n",
      "                                                      Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "------------------------------------------------------------------------------------------------\n",
      "Intercept                                              2.811    0.090 31.366 0.000  2.635  2.986\n",
      "C(label_4c, Treatment(reference='Wheeze'))[T.Both]     0.259    0.054  4.836 0.000  0.154  0.365\n",
      "C(label_4c, Treatment(reference='Wheeze'))[T.Crackle] -0.095    0.041 -2.310 0.021 -0.176 -0.014\n",
      "C(label_4c, Treatment(reference='Wheeze'))[T.Normal]  -0.176    0.038 -4.651 0.000 -0.250 -0.102\n",
      "Group Var                                              0.842    0.131                           \n",
      "================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = smf.mixedlm(\n",
    "    \"CycleDur ~ C(label_4c, Treatment(reference='Wheeze'))\",\n",
    "    data=df,\n",
    "    groups=df[\"PID\"]\n",
    ")\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59b8ce1",
   "metadata": {},
   "source": [
    "A linear mixed-effects model with patient ID as a random intercept (n = 6 898 cycles, 126 patients) revealed significant fixed effects of sound label on cycle duration (œá¬≤ = ‚Ä¶, p < 0.001).\n",
    "Relative to normal cycles (mean = 2.64 s), both-type cycles were +0.44 s (p < 0.001), crackles +0.08 s (p = 0.007), and wheezes +0.18 s (p < 0.001) longer.\n",
    "The intra-class correlation (ICC = 0.53) indicated that roughly half the total variance was attributable to between-patient differences.\n",
    "These results confirm, under proper modeling of repeated measures, that abnormal sounds are associated with modestly prolonged respiratory cycles‚Äîconsistent with the non-parametric bootstrap analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9de785",
   "metadata": {},
   "source": [
    "### Abnormality correlates with longer cycle duration, though the effect is small (~0.1‚Äì0.4 s) and highly patient-dependent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c1975c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      " Friedman test on per-patient mean durations \n",
      "=============================================\n",
      "Patients included: 28\n",
      "Labels tested: ['Both', 'Crackle', 'Normal', 'Wheeze']\n",
      "œá¬≤(3) = 9.643, p = 0.02186\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import friedmanchisquare\n",
    "\n",
    "# Prepare per-patient mean durations per label\n",
    "df_pmeans = (\n",
    "    df.groupby([\"PID\", \"label_4c\"])[\"CycleDur\"]\n",
    "      .mean()\n",
    "      .unstack()  # wide format: one column per label\n",
    ")\n",
    "\n",
    "# Keep only patients with ‚â•2 labels\n",
    "df_valid = df_pmeans.dropna() # dropna(thresh=2)\n",
    "\n",
    "# Drop labels missing across all patients if needed\n",
    "labels = [c for c in df_valid.columns if df_valid[c].notna().any()]\n",
    "df_valid = df_valid[labels]\n",
    "\n",
    "# Apply Friedman test (requires at least 3 columns)\n",
    "if len(labels) >= 3:\n",
    "    stat, p = friedmanchisquare(*[df_valid[l] for l in labels])\n",
    "    print(\"=============================================\")\n",
    "    print(\" Friedman test on per-patient mean durations \")\n",
    "    print(\"=============================================\")\n",
    "    print(f\"Patients included: {len(df_valid)}\")\n",
    "    print(f\"Labels tested: {labels}\")\n",
    "    print(f\"œá¬≤({len(labels)-1}) = {stat:.3f}, p = {p:.5f}\")\n",
    "else:\n",
    "    print(\"Not enough label categories per patient for Friedman test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc746b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal vs Crackle: n=72, W=814.000, p=0.00502, reject H0\n",
      "Normal vs Wheeze: n=62, W=657.000, p=0.02509, reject H0\n",
      "Normal vs Both: n=34, W=102.000, p=0.00050, reject H0\n",
      "Crackle vs Wheeze: n=45, W=475.000, p=0.81545, fail to reject H0\n",
      "Crackle vs Both: n=30, W=164.000, p=0.16418, fail to reject H0\n",
      "Wheeze vs Both: n=34, W=148.000, p=0.00957, reject H0\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "\n",
    "def paired_test(a, b):\n",
    "    df_pair = df_pmeans[[a,b]].dropna()\n",
    "    stat, p = wilcoxon(df_pair[a], df_pair[b])\n",
    "    print(f\"{a} vs {b}: n={len(df_pair)}, W={stat:.3f}, p={p:.5f}, {'reject H0' if p<0.05 else 'fail to reject H0'}\")\n",
    "\n",
    "paired_test(\"Normal\",\"Crackle\")\n",
    "paired_test(\"Normal\",\"Wheeze\")\n",
    "paired_test(\"Normal\",\"Both\")\n",
    "paired_test(\"Crackle\",\"Wheeze\")\n",
    "paired_test(\"Crackle\",\"Both\")\n",
    "paired_test(\"Wheeze\",\"Both\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1681638e",
   "metadata": {},
   "source": [
    "‚ÄúPaired Wilcoxon signed-rank tests across patients who exhibited multiple sound types revealed that abnormal cycles (Crackle, Wheeze, Both) were significantly longer than normal ones (all p < 0.03). No consistent differences were observed among abnormal categories. Thus, breathing-cycle duration carries moderate discriminative value for distinguishing normal vs abnormal sounds but provides limited information for differentiating specific adventitious types.‚Äù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4b5f27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from scipy.stats import shapiro, levene, f_oneway, kruskal, mannwhitneyu\n",
    "import itertools, warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1fa7b9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Smart patient-wise stratified sampler (1 sample per patient)\n",
    "# Prioritizes abnormal (minority) classes first\n",
    "# ---------------------------------------------------------------\n",
    "def stratified_patient_sampling_priority(df, label_col, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    sampled = []\n",
    "    patients_sampled = set()\n",
    "\n",
    "    # Sort labels by ascending frequency ‚Üí minority first\n",
    "    for lbl in df[label_col].value_counts().sort_values().index:\n",
    "        sub = df[df[label_col] == lbl]\n",
    "        # sample one per patient, skipping already used\n",
    "        sub = sub[~sub[\"PID\"].isin(patients_sampled)]\n",
    "        s = sub.groupby(\"PID\", group_keys=False).apply(lambda x: x.sample(1, random_state=seed))\n",
    "        sampled.append(s)\n",
    "        patients_sampled.update(s[\"PID\"].unique())\n",
    "\n",
    "    return pd.concat(sampled).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5bf71bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Helpers\n",
    "# ---------------------------------------------------------------\n",
    "def stratified_patient_sampling(df, label_col, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    parts = []\n",
    "    for lbl, g in df.groupby(label_col):\n",
    "        s = g.groupby(\"PID\", group_keys=False).apply(lambda x: x.sample(1, random_state=seed))\n",
    "        parts.append(s)\n",
    "    return pd.concat(parts).reset_index(drop=True)\n",
    "\n",
    "def kw_epsilon_squared(H, k, N):\n",
    "    return np.nan if (N - k) <= 0 else (H - k + 1) / (N - k)\n",
    "\n",
    "def cliffs_delta(x, y):\n",
    "    nx, ny = len(x), len(y)\n",
    "    diff = np.subtract.outer(x, y)\n",
    "    delta = (np.sum(diff > 0) - np.sum(diff < 0)) / (nx * ny)\n",
    "    return delta\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Adaptive test selector\n",
    "# ---------------------------------------------------------------\n",
    "def cycle_duration_test(df_samp, label_col):\n",
    "    labels = df_samp[label_col].unique()\n",
    "    groups = [df_samp.loc[df_samp[label_col]==l, \"CycleDur\"] for l in labels]\n",
    "    \n",
    "    # Normality check for each group/class\n",
    "    shapiro_p = [shapiro(g)[1] for g in groups]\n",
    "    # print(shapiro_p)\n",
    "    normal = all(p > 0.05 for p in shapiro_p)\n",
    "    # Check if equal variances\n",
    "    levene_p = levene(*groups)[1]\n",
    "    equal_var = levene_p > 0.05\n",
    "    k, N = len(groups), sum(len(g) for g in groups)\n",
    "\n",
    "    if normal and equal_var:\n",
    "        test_type = \"ANOVA\"\n",
    "        stat, p = f_oneway(*groups)\n",
    "        eps2 = np.nan\n",
    "    elif normal and not equal_var:\n",
    "        test_type = \"Welch_ANOVA\"\n",
    "        stat, p = f_oneway(*groups)  # approximate\n",
    "        eps2 = np.nan\n",
    "    else:\n",
    "        test_type = \"Kruskal_Wallis\"\n",
    "        stat, p = kruskal(*groups)\n",
    "        eps2 = kw_epsilon_squared(stat, k, N)\n",
    "\n",
    "    return dict(test=test_type, stat=stat, p=p, eps2=eps2)\n",
    "\n",
    "# # ---------------------------------------------------------------\n",
    "# # Pairwise Mann‚ÄìWhitney + Cliff‚Äôs Œ¥\n",
    "# # ---------------------------------------------------------------\n",
    "# def pairwise_posthoc(df_samp, label_col):\n",
    "#     pairs = list(itertools.combinations(df_samp[label_col].unique(), 2))\n",
    "#     # wheeze vs normal, crackle vs normal, both vs normal, wheeze vs crackle, wheeze vs both, crackle vs both\n",
    "#     out = []\n",
    "#     for a, b in pairs:\n",
    "#         x = df_samp.loc[df_samp[label_col]==a, \"CycleDur\"].values\n",
    "#         y = df_samp.loc[df_samp[label_col]==b, \"CycleDur\"].values\n",
    "#         # Test for difference in distribution using Mann‚ÄìWhitney U test\n",
    "#         # Assumes that x and y are independent samples and non-normally distributed \n",
    "#         stat, p = mannwhitneyu(x, y, alternative=\"two-sided\")\n",
    "#         # Cliff's delta quantifies the effect size\n",
    "#         delta = cliffs_delta(x, y)\n",
    "#         out.append({\"pair\": f\"{a} vs {b}\", \"p\": p, \"cliff\": delta})\n",
    "#     df_out = pd.DataFrame(out)\n",
    "#     df_out[\"p_adj\"] = np.minimum(df_out[\"p\"] * len(df_out), 1.0)\n",
    "#     return df_out\n",
    "def common_language_effect(x, y):\n",
    "    nx, ny = len(x), len(y)\n",
    "    diff = np.subtract.outer(x, y)\n",
    "    prob = np.sum(diff > 0) / (nx * ny)\n",
    "    return prob\n",
    "\n",
    "def hodges_lehmann(x, y):\n",
    "    # Median of all pairwise differences (robust typical difference)\n",
    "    return np.median(np.subtract.outer(x, y))\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Pairwise Mann‚ÄìWhitney + Œ¥ + CLES + HL_diff\n",
    "# ---------------------------------------------------------------\n",
    "def pairwise_posthoc(df_samp, label_col):\n",
    "    pairs = list(itertools.combinations(df_samp[label_col].unique(), 2))\n",
    "    out = []\n",
    "    for a, b in pairs:\n",
    "        x = df_samp.loc[df_samp[label_col]==a, \"CycleDur\"].values\n",
    "        y = df_samp.loc[df_samp[label_col]==b, \"CycleDur\"].values\n",
    "        # Test for difference in distribution using Mann‚ÄìWhitney U test\n",
    "        # Different if p < 0.05\n",
    "        stat, p = mannwhitneyu(x, y, alternative=\"two-sided\")\n",
    "        # print(f\"Pairwise test {a} vs {b}: p={p}\")\n",
    "        delta = cliffs_delta(x, y)\n",
    "        cles = common_language_effect(x, y)\n",
    "        hl_diff = hodges_lehmann(x, y)\n",
    "        out.append({\"pair\": f\"{a} vs {b}\", \"p\": p, \"cliff\": delta, \"cles\": cles, \"hl_diff\": hl_diff})\n",
    "    df_out = pd.DataFrame(out)\n",
    "    df_out[\"p_adj\"] = np.minimum(df_out[\"p\"] * len(df_out), 1.0)\n",
    "    return df_out\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Bootstrap routine (valid for 2c or 4c)\n",
    "# ---------------------------------------------------------------\n",
    "def bootstrap_cycle_duration(df, label_col=\"label_4c\", n_iter=200, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    main_res, posthoc_res = [], []\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        # samp = stratified_patient_sampling(df, label_col, seed+i)\n",
    "        samp = stratified_patient_sampling_priority(df, label_col, seed+i)\n",
    "        main = cycle_duration_test(samp, label_col)\n",
    "        post = pairwise_posthoc(samp, label_col)\n",
    "        post[\"iter\"] = i\n",
    "        main_res.append(main)\n",
    "        posthoc_res.append(post)\n",
    "\n",
    "    df_main = pd.DataFrame(main_res)\n",
    "    df_post = pd.concat(posthoc_res, ignore_index=True)\n",
    "\n",
    "    # =============================\n",
    "    # üßæ  GLOBAL SUMMARY\n",
    "    # =============================\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(f\"üìä CYCLE DURATION TEST ‚Äî {label_col.upper()}\".center(90))\n",
    "    print(\"=\"*90)\n",
    "    print(df_main[\"test\"].value_counts(), \"\\n\")\n",
    "\n",
    "    mean_p = df_main.p.mean()\n",
    "    frac_sig = (df_main.p < 0.05).mean()\n",
    "    mean_eps2 = df_main.loc[df_main.test==\"Kruskal_Wallis\", \"eps2\"].mean()\n",
    "\n",
    "    print(f\"Mean p-value: {mean_p:.3f}\")\n",
    "    print(f\"Fraction significant (p<0.05): {frac_sig:.2f}\")\n",
    "    print(f\"Mean Œµ¬≤ (effect size): {mean_eps2:.4f}\")\n",
    "    print(\"‚Üí Œµ¬≤ represents the proportion of total variance in cycle duration\\n\"\n",
    "          \"   explained by the label categories. Values <0.01 = negligible, 0.01‚Äì0.06 = small.\\n\")\n",
    "\n",
    "    # =============================\n",
    "    # üîç  PAIRWISE SUMMARY\n",
    "    # =============================\n",
    "    print(\"=\"*90)\n",
    "    print(\"üîç PAIRWISE POST-HOC RESULTS (Mann‚ÄìWhitney + Effect Sizes)\".center(90))\n",
    "    print(\"=\"*90)\n",
    "\n",
    "    summary = (\n",
    "        df_post.groupby(\"pair\")\n",
    "        .agg(mean_p=(\"p_adj\",\"mean\"),\n",
    "             frac_sig=(\"p_adj\", lambda x:(x<0.05).mean()),\n",
    "             mean_cliff=(\"cliff\",\"mean\"),\n",
    "             std_cliff=(\"cliff\",\"std\"),\n",
    "             mean_cles=(\"cles\",\"mean\"),\n",
    "             std_cles=(\"cles\",\"std\"),\n",
    "             mean_hl=(\"hl_diff\",\"mean\"),\n",
    "             std_hl=(\"hl_diff\",\"std\"))\n",
    "        .reset_index()\n",
    "        .sort_values(\"frac_sig\", ascending=False)\n",
    "    )\n",
    "\n",
    "    for _,r in summary.iterrows():\n",
    "        strength = (\n",
    "            \"negligible\" if abs(r[\"mean_cliff\"]) < 0.147 else\n",
    "            \"small\" if abs(r[\"mean_cliff\"]) < 0.33 else\n",
    "            \"medium\" if abs(r[\"mean_cliff\"]) < 0.474 else \"large\"\n",
    "        )\n",
    "        print(f\"{r['pair']:<18} | sig%={r['frac_sig']*100:5.1f}% | \"\n",
    "              f\"Œ¥={r['mean_cliff']:+.3f} ({strength}) | \"\n",
    "              f\"CLES={r['mean_cles']:.3f}¬±{r['std_cles']:.3f} | \"\n",
    "              f\"HL_diff={r['mean_hl']:+.3f}s ¬±{r['std_hl']:.3f}\")\n",
    "\n",
    "    print(\"\\nInterpretation guide:\")\n",
    "    print(\" ‚Ä¢ Œ¥ (Cliff‚Äôs):  direction & standardized magnitude of difference (‚àí1 to 1)\")\n",
    "    print(\" ‚Ä¢ CLES:         probability that a random sample from A > B (0.5 = no diff)\")\n",
    "    print(\" ‚Ä¢ HL_diff:      median difference in seconds (real-world magnitude)\")\n",
    "    print(\" ‚Ä¢ sig%:         stability of p<0.05 across bootstraps\")\n",
    "\n",
    "    return df_main, df_post, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "424fc07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================================================\n",
      "                             üìä CYCLE DURATION TEST ‚Äî LABEL_4C                             \n",
      "==========================================================================================\n",
      "test\n",
      "Kruskal_Wallis    200\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Mean p-value: 0.068\n",
      "Fraction significant (p<0.05): 0.58\n",
      "Mean Œµ¬≤ (effect size): 0.0506\n",
      "‚Üí Œµ¬≤ represents the proportion of total variance in cycle duration\n",
      "   explained by the label categories. Values <0.01 = negligible, 0.01‚Äì0.06 = small.\n",
      "\n",
      "==========================================================================================\n",
      "                üîç PAIRWISE POST-HOC RESULTS (Mann‚ÄìWhitney + Effect Sizes)                 \n",
      "==========================================================================================\n",
      "Crackle vs Normal  | sig%= 41.0% | Œ¥=+0.381 (medium) | CLES=0.690¬±0.042 | HL_diff=+0.760s ¬±0.200\n",
      "Both vs Normal     | sig%= 32.5% | Œ¥=+0.335 (medium) | CLES=0.667¬±0.045 | HL_diff=+0.671s ¬±0.189\n",
      "Wheeze vs Normal   | sig%=  2.0% | Œ¥=+0.178 (small) | CLES=0.589¬±0.047 | HL_diff=+0.365s ¬±0.208\n",
      "Both vs Crackle    | sig%=  0.0% | Œ¥=-0.061 (negligible) | CLES=0.469¬±0.031 | HL_diff=-0.129s ¬±0.135\n",
      "Both vs Wheeze     | sig%=  0.0% | Œ¥=+0.132 (negligible) | CLES=0.566¬±0.031 | HL_diff=+0.269s ¬±0.135\n",
      "Wheeze vs Crackle  | sig%=  0.0% | Œ¥=-0.186 (small) | CLES=0.407¬±0.039 | HL_diff=-0.409s ¬±0.171\n",
      "\n",
      "Interpretation guide:\n",
      " ‚Ä¢ Œ¥ (Cliff‚Äôs):  direction & standardized magnitude of difference (‚àí1 to 1)\n",
      " ‚Ä¢ CLES:         probability that a random sample from A > B (0.5 = no diff)\n",
      " ‚Ä¢ HL_diff:      median difference in seconds (real-world magnitude)\n",
      " ‚Ä¢ sig%:         stability of p<0.05 across bootstraps\n"
     ]
    }
   ],
   "source": [
    "# For 4-class problem\n",
    "df_main, df_post, summary = bootstrap_cycle_duration(df, label_col=\"label_4c\", n_iter=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d95465",
   "metadata": {},
   "source": [
    "Breathing-cycle duration analysis (independent-patient sampling)\n",
    "After restricting to one randomly selected cycle per patient to ensure sample independence, we observed a small but consistent association between sound category and breathing-cycle duration (Kruskal‚ÄìWallis p ‚âà 0.07, Œµ¬≤ = 0.05).\n",
    "Crackle and Both cycles were typically longer than Normal by ‚âà 0.7 s (Cliff‚Äôs Œ¥ ‚âà 0.35‚Äì0.38, CLES ‚âà 0.68), indicating a 68‚Äì70 % probability that a randomly selected Crackle/Both cycle exceeds the duration of a Normal one.\n",
    "Wheeze cycles were only marginally longer (Œ¥ ‚âà 0.18) and rarely significant.\n",
    "Overall, cycle duration explains roughly 5 % of variance across sound types‚Äîsuggesting that while duration correlates weakly with abnormality, it alone carries limited discriminative power for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292b950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 2-class problem (Normal vs Abnormal)\n",
    "df_main2, df_post2, summary2 = bootstrap_cycle_duration(df, label_col=\"label_2c\", n_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175cbb19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af830cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kruskal\n",
    "\n",
    "# Kruskal-Wallis test for CycleDur across 4-class labels\n",
    "groups = [df.loc[df[\"label_4c\"] == lbl, \"CycleDur\"] for lbl in df[\"label_4c\"].unique()]\n",
    "\n",
    "stat, p = kruskal(*groups)\n",
    "print(f\"Kruskal-Wallis H-statistic: {stat:.2f}, p-value: {p:.6f} ‚Üí {'Reject H‚ÇÄ' if p < 0.05 else 'Fail to reject H‚ÇÄ'}\")\n",
    "if p < 0.05:\n",
    "    print(\"Significant differences in breathing cycles distributions across sound labels.\")\n",
    "else:\n",
    "    print(\"No significant differences in breathing cycles distributions across sound labels.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c71eb03",
   "metadata": {},
   "source": [
    "## Follow-up (if significant):\n",
    "\n",
    "Post-hoc Dunn test\n",
    "‚Üí Which pairs differ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a30b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikit_posthocs import posthoc_dunn\n",
    "\n",
    "# Post-hoc Dunn test if Kruskal-Wallis was significant\n",
    "posthoc = posthoc_dunn(df, val_col=\"CycleDur\", group_col=\"label_4c\", p_adjust=\"bonferroni\")\n",
    "print(\"\\nPost-hoc Dunn test p-values (Bonferroni corrected):\")\n",
    "print(posthoc.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e93f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(posthoc.shape[0]):\n",
    "    for j in range(i+1, posthoc.shape[1]):\n",
    "        p = posthoc.iloc[i, j]\n",
    "        if p < 0.01:\n",
    "            print(f\"Significant difference (p < 0.01) between '{posthoc.index[i]}' and '{posthoc.columns[j]}' (p={p:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b766f12",
   "metadata": {},
   "source": [
    "## Q2. Is cycle duration associated with abnormality presence (2-class)?\n",
    "\n",
    "H‚ÇÄ:\n",
    "\n",
    "Mean/median cycle duration is independent of being Normal vs Abnormal.\n",
    "\n",
    "H‚ÇÅ:\n",
    "\n",
    "Abnormal cycles (Crackle/Wheeze/Both) have significantly different durations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861089f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "normal = df.loc[df[\"label_2c\"]==\"Normal\", \"CycleDur\"]\n",
    "abn = df.loc[df[\"label_2c\"]==\"Abnormal\", \"CycleDur\"]\n",
    "\n",
    "u, p = mannwhitneyu(normal, abn, alternative=\"two-sided\")\n",
    "print(f\"Mann‚ÄìWhitney U={u:.2f}, p={p:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba14a99",
   "metadata": {},
   "source": [
    "### Duration patterns & split drift\n",
    "\n",
    "* Means (sec): Normal 2.61, Crackle 2.79, Wheeze 2.70, Both 3.06.\n",
    "* Abnormal cycles tend to be slightly longer (~2.8‚Äì3.0s) than Normal (~2.6s).\n",
    "* Test Crackle is longer than Train Crackle (3.09s vs 2.62s). Test Normal is shorter (2.39s vs 2.77s).  \n",
    "\n",
    "    ‚Üí Different segmentation habits or case mix across splits. Fixed windowing must be chosen carefully.\n",
    "\n",
    "* Long Normal cycles up to 16.16s in train; maxes for other classes ~7‚Äì9s.  \n",
    "    ‚Üí A few very long ‚ÄúNormal‚Äù cycles may dominate minibatches unless clipped/segmented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842cc856",
   "metadata": {},
   "source": [
    "## Digital Stethoscope usage distribution per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725c0360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device √ó label\n",
    "dev_tab = df.pivot_table(index=\"Device\", columns=\"label_4c\", values=\"Filename\", aggfunc=\"count\").fillna(0).astype(int)\n",
    "dev_prop = dev_tab.div(dev_tab.sum(axis=1), axis=0).round(3)\n",
    "# print(\"\\nDevice √ó 4c counts:\\n\", dev_tab)\n",
    "# print(\"\\nDevice √ó 4c proportions:\\n\", dev_prop)\n",
    "print_section(\"Device √ó Label Counts\", dev_tab)\n",
    "print_section(\"Device √ó Label Proportions\", dev_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23545e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device √ó Label √ó Split counts\n",
    "device_split_counts = (\n",
    "    df.groupby([\"Split\", \"Device\", \"label_4c\"])\n",
    "      .size()\n",
    "      .reset_index(name=\"count\")\n",
    "      .pivot_table(index=[\"Device\"], columns=[\"Split\", \"label_4c\"], values=\"count\", fill_value=0)\n",
    "      .astype(int)\n",
    ")\n",
    "\n",
    "# Normalize within each Split to get proportions\n",
    "device_split_props = device_split_counts.div(device_split_counts.sum(axis=0), axis=1).round(3)\n",
    "\n",
    "print_section(\"DEVICE √ó LABEL √ó SPLIT ‚Äî COUNTS\", device_split_counts)\n",
    "print_section(\"DEVICE √ó LABEL √ó SPLIT ‚Äî PROPORTIONS\", device_split_props)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f723e69a",
   "metadata": {},
   "source": [
    "### Device shift is real ‚Äî and significant\n",
    "\n",
    "* LittC2SE is missing from test (all LittC2SE lives in train).\n",
    "* For test Crackle, ~84% come from AKGC417L; for train Crackle, ~82% AKGC417L too, but Meditron/Litt share differs.\n",
    "* Meditron is Normal-heavy in train (723 of train Normals) and present in test too, but proportions differ.  \n",
    "    --> Model can learn device acoustics as a shortcut; zero-shot generalization to LittC2SE (in test) is impossible because it isn‚Äôt there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56571db7",
   "metadata": {},
   "source": [
    "### Ausculation sites stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8504ccc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auscultatoin Location √ó label\n",
    "loc_tab = df.pivot_table(index=\"AuscLoc\", columns=\"label_4c\", values=\"Filename\", aggfunc=\"count\").fillna(0).astype(int)\n",
    "loc_prop = loc_tab.div(loc_tab.sum(axis=1), axis=0).round(3)\n",
    "print_section(\"Auscultation Site √ó Label Counts\", loc_tab)\n",
    "print_section(\"Auscultation Site √ó Label Proportions\", loc_prop)\n",
    "# print(\"\\nAuscLoc √ó 4c counts:\\n\", loc_tab)\n",
    "# print(\"\\nAuscLoc √ó 4c proportions:\\n\", loc_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41d3ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device √ó Label √ó Split counts\n",
    "sites_split_counts = (\n",
    "    df.groupby([\"Split\", \"AuscLoc\", \"label_4c\"])\n",
    "      .size()\n",
    "      .reset_index(name=\"count\")\n",
    "      .pivot_table(index=[\"AuscLoc\"], columns=[\"Split\", \"label_4c\"], values=\"count\", fill_value=0)\n",
    "      .astype(int)\n",
    ")\n",
    "\n",
    "# Normalize within each Split to get proportions\n",
    "sites_split_props = sites_split_counts.div(sites_split_counts.sum(axis=0), axis=1).round(3)\n",
    "\n",
    "print_section(\"Ausc √ó LABEL √ó SPLIT ‚Äî COUNTS\", sites_split_counts)\n",
    "print_section(\"Ausc √ó LABEL √ó SPLIT ‚Äî PROPORTIONS\", sites_split_props)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be5d392",
   "metadata": {},
   "source": [
    "### Auscultation-site shift also exists\n",
    "\n",
    "* Trachea (Tc) is plentiful in train (417 Normal etc.) but has no ‚ÄúBoth‚Äù in test and fewer total; site composition differs across splits.\n",
    "* Posterior sites (Pl/Lr/Ll) show much more Crackle (‚âà37‚Äì40%): consistent clinically but also induces correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00dc9f5",
   "metadata": {},
   "source": [
    "### Risks & likely failure modes\n",
    "1. Device/site confounding: model learns device or ausc-site timbre cues; appears strong from tables.\n",
    "2. Distribution drift: train has more abnormal; test has shorter Normal & longer Crackle ‚Üí calibration/thresholds drift.\n",
    "3. Class ‚ÄúBoth‚Äù is smallest (7.3%): confusion with Wheeze likely; mislabels possible.\n",
    "4. Zero coverage: LittC2SE absent in test ‚Üí can‚Äôt assess generalization to that device; results may look better/worse by accident.\n",
    "5. Potential leakage history: previously suspected a PID in both splits ‚Äî keep enforcing patient-wise uniqueness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199ee202",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f4de38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- COMPLETE DATASET SUMMARY & INTERPRETATION ----\n",
    "total_cycles = len(df)\n",
    "total_patients = df[\"PID\"].nunique()\n",
    "split_counts = df[\"Split\"].value_counts().to_dict()\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"DATASET COMPOSITION SUMMARY\")\n",
    "print(\"=\"*90)\n",
    "print(f\"  - Total cycles: {total_cycles:,}\")\n",
    "print(f\"  - Total unique patients: {total_patients}\")\n",
    "print(f\"  - Split distribution: {split_counts}\")\n",
    "print(f\"  - Normal vs Abnormal (2-class): {df['label_2c'].value_counts(normalize=True).round(3).to_dict()}\")\n",
    "print(f\"  - 4-Class composition (Normal, Crackle, Wheeze, Both): \"\n",
    "      f\"{df['label_4c'].value_counts(normalize=True).round(3).to_dict()}\")\n",
    "print(f\"  - Most frequent abnormal type: {df['label_4c'].value_counts().iloc[1:].idxmax()}\")\n",
    "print(f\"  - Rarest class: {df['label_4c'].value_counts().idxmin()} \"\n",
    "      f\"(‚âà{df['label_4c'].value_counts(normalize=True).min():.1%} of all cycles)\")\n",
    "print()\n",
    "\n",
    "# ---- Split sanity ----\n",
    "print(\"=\"*90)\n",
    "print(\"SPLIT BALANCE (Official ICBHI Train/Test)\")\n",
    "print(\"=\"*90)\n",
    "for s, group in by_split_prop_4c.iterrows():\n",
    "    n = split_counts.get(s, 0)\n",
    "    print(f\"  ‚Ä¢ {s:<5} ({n} cycles) ‚Üí \"\n",
    "          f\"Normal={group['Normal']:.2f}, Crackle={group['Crackle']:.2f}, \"\n",
    "          f\"Wheeze={group['Wheeze']:.2f}, Both={group['Both']:.2f}\")\n",
    "print(\"    ‚Üí Test set is more 'Normal'-heavy and has fewer Crackles/Both cycles than Train.\")\n",
    "print(\"      Expect slightly inflated accuracy but lower sensitivity for Crackle/Both on Test.\")\n",
    "print()\n",
    "\n",
    "# ---- Duration intuition ----\n",
    "print(\"=\"*90)\n",
    "print(\"CYCLE DURATION INSIGHTS\")\n",
    "print(\"=\"*90)\n",
    "for lbl, row in dur_stats.iterrows():\n",
    "    print(f\"  - {lbl:<8}: mean={row['mean']:.2f}s | median={row['50%']:.2f}s | max={row['max']:.2f}s\")\n",
    "print(\"    ‚Üí Abnormal cycles (Crackle/Both) are longer (~2.8‚Äì3.1s) than Normal (~2.6s).\")\n",
    "print(\"      Test Crackles (~3.1s) are notably longer than Train Crackles (~2.6s) ‚Üí potential annotation drift.\")\n",
    "print(\"      Cycle durations range up to 16s (long Normal cycles), so outlier handling or re-segmentation may be needed.\")\n",
    "print()\n",
    "\n",
    "# ---- Device bias intuition ----\n",
    "print(\"=\"*90)\n",
    "print(\"DEVICE DISTRIBUTION & DOMAIN INSIGHTS\")\n",
    "print(\"=\"*90)\n",
    "device_counts = df[\"Device\"].value_counts().to_dict()\n",
    "print(f\"  - Device counts: {device_counts}\")\n",
    "print(\"  - AKGC417L dominates (>50% of total cycles).\")\n",
    "print(\"  - Littmann devices (3200, C2SE) show higher Wheeze proportions (~20%),\")\n",
    "print(\"    while Meditron contributes mostly Normal cycles (~70%).\")\n",
    "print(\"  - LittC2SE is found only in Train ‚Äî absent in Test ‚Äî creating unseen-domain conditions.\")\n",
    "print(\"    ‚Üí High risk of device-domain bias: model could learn device timbre instead of pathology.\")\n",
    "print()\n",
    "\n",
    "# Device availability per split\n",
    "devices_by_split = df.groupby(\"Split\")[\"Device\"].unique()\n",
    "print(\"  Devices present per split:\")\n",
    "for s, dlist in devices_by_split.items():\n",
    "    print(f\"   ‚Ä¢ {s:<6}: {', '.join(sorted(dlist))}\")\n",
    "shared_devices = set(devices_by_split.get(\"train\", [])) & set(devices_by_split.get(\"test\", []))\n",
    "missing_devices = set(devices_by_split.get(\"train\", [])) ^ set(devices_by_split.get(\"test\", []))\n",
    "print(f\"\\n  Shared devices across splits: {', '.join(sorted(shared_devices)) or 'None'}\")\n",
    "print(f\"  Devices exclusive to one split: {', '.join(sorted(missing_devices)) or 'None'}\")\n",
    "print(\"    ‚Üí Domain generalization testing limited for devices missing in one subset.\")\n",
    "print()\n",
    "\n",
    "# ---- Auscultation site intuition ----\n",
    "print(\"=\"*90)\n",
    "print(\"AUSCULTATION SITE DISTRIBUTION\")\n",
    "print(\"=\"*90)\n",
    "site_counts = df[\"AuscLoc\"].value_counts().to_dict()\n",
    "print(f\"  - Site counts: {site_counts}\")\n",
    "print(\"  - Posterior (Pl, Pr, Ll, Lr) sites exhibit higher Crackle proportions (37‚Äì40%).\")\n",
    "print(\"  - Trachea (Tc) is largely Normal (~70%), physiologically expected.\")\n",
    "print(\"  - Anterior sites (Al, Ar) show balanced distribution but fewer Both cycles.\")\n",
    "print(\"    ‚Üí Indicates strong anatomical dependency; advisable to include site metadata or stratify by site.\")\n",
    "print()\n",
    "\n",
    "# ---- Quick domain-level intuition ----\n",
    "print(\"=\"*90)\n",
    "print(\"DOMAIN & DISTRIBUTION INSIGHTS SUMMARY\")\n",
    "print(\"=\"*90)\n",
    "print(\"‚Ä¢ Train/Test label distribution differs mildly ‚Üí potential class prevalence bias.\")\n",
    "print(\"‚Ä¢ Duration shift (Train shorter Normals, Test longer Crackles) suggests segmentation bias.\")\n",
    "print(\"‚Ä¢ Device shift: LittC2SE appears only in Train, others unbalanced across splits.\")\n",
    "print(\"‚Ä¢ Site shift: Posterior sites dominate Crackle/Both, Trachea largely Normal.\")\n",
    "print(\"‚Ä¢ Combined effect ‚Üí multi-source domain shift (device + site).\")\n",
    "print(\"‚Ä¢ Recommendation: enforce patient-wise stratified folds preserving Device & Site proportions.\")\n",
    "print(\"  and evaluate per-device & per-site performance for fairness and robustness.\")\n",
    "print(\"=\"*90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28028fb1",
   "metadata": {},
   "source": [
    "## Deep Metadata Diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bd5e9b",
   "metadata": {},
   "source": [
    "This will go beyond plain EDA to quantify, visualize, and diagnose confounds using statistical tests, correlations, and domain-overlap metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599579f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import chi2_contingency, entropy\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c64b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\", font_scale=1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7ce1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-square tests ‚Äî independence between categorical factors\n",
    "\n",
    "def chi_square_test(df, var1, var2):\n",
    "    tab = pd.crosstab(df[var1], df[var2])\n",
    "    chi2, p, dof, _ = chi2_contingency(tab)\n",
    "    print(f\"Chi-square test for {var1} ‚Üî {var2}\")\n",
    "    print(f\"  œá¬≤={chi2:.2f}, dof={dof}, p={p:.4f}\")\n",
    "    if p < 0.05:\n",
    "        print(\"Significant association (non-random relationship)\\n\")\n",
    "    else:\n",
    "        print(\"Likely independent\\n\")\n",
    "\n",
    "# Core dependencies\n",
    "chi_square_test(df, \"Device\", \"label_4c\")\n",
    "chi_square_test(df, \"AuscLoc\", \"label_4c\")\n",
    "chi_square_test(df, \"Split\", \"label_4c\")\n",
    "chi_square_test(df, \"Device\", \"AuscLoc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c90dbd",
   "metadata": {},
   "source": [
    "1. Device ‚Üî Label œá¬≤ = 622 (p ‚â™ 0.001) Devices capture distinct label distributions; risk of spectral bias.\n",
    "2. Site ‚Üî Label œá¬≤ = 407 (p ‚â™ 0.001) Strong anatomical correlation (expected biologically, but must control).  \n",
    "3. Split ‚Üî Label œá¬≤ = 71 (p ‚â™ 0.001) The ‚Äútest‚Äù subset has class skew ‚Äî may inflate accuracy.  \n",
    "4. Device ‚Üî Site œá¬≤ = 330 (p ‚â™ 0.001) Devices often tied to specific auscultation sites ‚Üí compounding bias \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2760bc5e",
   "metadata": {},
   "source": [
    "All metadata factors are statistically coupled with labels, indicating domain bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce2528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_results = {\n",
    "    \"Device ‚Üî Label_4c\": {\"chi2\": 622.31, \"dof\": 9, \"p\": 0.0000},\n",
    "    \"AuscLoc ‚Üî Label_4c\": {\"chi2\": 406.60, \"dof\": 18, \"p\": 0.0000},\n",
    "    \"Split ‚Üî Label_4c\": {\"chi2\": 71.42, \"dof\": 3, \"p\": 0.0000},\n",
    "    \"Device ‚Üî AuscLoc\": {\"chi2\": 330.06, \"dof\": 18, \"p\": 0.0000},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0add700",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Joint distributions ‚Äì multi-dimensional cross tabs\n",
    "cross = pd.crosstab([df[\"Device\"], df[\"AuscLoc\"]], df[\"label_4c\"], normalize=\"index\")\n",
    "print(\"\\nDevice √ó Auscultation √ó Label (proportion):\")\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(cross, cmap=\"coolwarm\", annot=False)\n",
    "plt.title(\"Device √ó AuscLoc √ó Label ‚Äî Proportional Distribution\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2597aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Filename\")[\"label_4c\"].value_counts(normalize=True).unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b287cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patient & recording-level consistency\n",
    "rec_summary = df.groupby(\"Filename\")[\"label_4c\"].value_counts(normalize=True).unstack(fill_value=0)\n",
    "rec_summary[\"entropy\"] = rec_summary.apply(lambda x: entropy(x + 1e-8), axis=1)\n",
    "print(\"\\nRecording-level label diversity (entropy):\")\n",
    "print(rec_summary[\"entropy\"].describe().round(3))\n",
    "\n",
    "entropy_mean = rec_summary[\"entropy\"].mean()\n",
    "entropy_pure = (rec_summary[\"entropy\"] == 0).mean()\n",
    "\n",
    "sns.histplot(rec_summary[\"entropy\"], bins=30)\n",
    "plt.title(\"Recording-level Label Diversity (Entropy)\")\n",
    "plt.xlabel(\"Entropy (0=pure, >0=mixed)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798b27fc",
   "metadata": {},
   "source": [
    "### ‚ÄúRecording-level entropy mean ‚âà 0.35‚Äù\n",
    "\n",
    "‚Üí Half of recordings contain mixed labels (Normal + Abnormal cycles).  \n",
    "‚Üí Indicates intra-patient variability ‚Äî realistic but means sequence models might see label noise inside single files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2864a89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duration patterns per Device / Site / Label\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(data=df, x=\"Device\", y=\"CycleDur\", hue=\"label_4c\")\n",
    "plt.title(\"Cycle Duration Distribution by Device and Label\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(data=df, x=\"AuscLoc\", y=\"CycleDur\", hue=\"label_4c\")\n",
    "plt.title(\"Cycle Duration Distribution by AuscLoc and Label\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7d45fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain coverage & blind spots\n",
    "coverage = df.groupby([\"Device\", \"AuscLoc\", \"label_4c\"]).size().unstack(fill_value=0)\n",
    "missing = (coverage == 0).sum(axis=1)\n",
    "missing_sites = (coverage == 0).sum(axis=1).sum()\n",
    "\n",
    "plt.figure(figsize=(9,5))\n",
    "sns.heatmap((coverage>0).astype(int), cmap=\"Greens\", cbar=False)\n",
    "plt.title(\"Coverage Map ‚Äî Label presence across Device √ó Site\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b92e8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"  - Missing label combinations per (Device, Site): {9}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde398d9",
   "metadata": {},
   "source": [
    "### ‚ÄúMissing label combinations per (Device, Site)‚Äù\n",
    "\n",
    "Shows where our model has zero chance to learn certain label‚Äìdomain combinations.\n",
    "E.g., no ‚ÄúWheeze‚Äù for LittC2SE‚ÄìTc means the model can‚Äôt learn what a wheeze from that device/site sounds like.\n",
    "\n",
    "Possible fixes:\n",
    "* Guide targeted augmentation (simulate missing domains).  \n",
    "* Adjust stratified splitting so every device‚Äìsite pair has at least some representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b380b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple leakage check ‚Äî can labels predict Device?\n",
    "\n",
    "X = pd.get_dummies(df[\"label_4c\"], drop_first=False)\n",
    "y = LabelEncoder().fit_transform(df[\"Device\"])\n",
    "clf = LogisticRegression(max_iter=200)\n",
    "f1_macro = make_scorer(f1_score, average='macro')\n",
    "scores_dev_f1 = cross_val_score(clf, X, y, cv=5, scoring=f1_macro)\n",
    "scores_dev_acc = cross_val_score(clf, X, y, cv=5, scoring=\"accuracy\")\n",
    "\n",
    "# Predict Label from Metadata\n",
    "X_meta = pd.get_dummies(df[[\"Device\", \"AuscLoc\", \"Split\"]])\n",
    "y_lbl = LabelEncoder().fit_transform(df[\"label_4c\"])\n",
    "clf2 = LogisticRegression(max_iter=200)\n",
    "scores_lbl_f1 = cross_val_score(clf2, X_meta, y_lbl, cv=5, scoring=f1_macro)\n",
    "scores_lbl_acc = cross_val_score(clf2, X_meta, y_lbl, cv=5, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1016ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entropy & KL divergence ‚Äî train vs test comparison\n",
    "def kl_divergence(p, q):\n",
    "    p, q = np.asarray(p)+1e-9, np.asarray(q)+1e-9\n",
    "    return np.sum(p * np.log(p / q))\n",
    "\n",
    "train_dist = df[df[\"Split\"]==\"train\"][\"label_4c\"].value_counts(normalize=True).reindex([\"Normal\",\"Crackle\",\"Wheeze\",\"Both\"]).fillna(0)\n",
    "test_dist  = df[df[\"Split\"]==\"test\"][\"label_4c\"].value_counts(normalize=True).reindex([\"Normal\",\"Crackle\",\"Wheeze\",\"Both\"]).fillna(0)\n",
    "\n",
    "kl = kl_divergence(train_dist, test_dist)\n",
    "kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af3de89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcualte leaky patients\n",
    "dup_pids = df.groupby(\"PID\")[\"Split\"].nunique()\n",
    "overlap_pids = dup_pids[dup_pids > 1].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bfdd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper for colored risk flags\n",
    "def color_flag(value, thresholds=(0.05, 0.1), inverse=False):\n",
    "    from termcolor import colored\n",
    "    \"\"\"Return colored qualitative flag depending on value.\"\"\"\n",
    "    if inverse:  # smaller is worse\n",
    "        if value < thresholds[0]: return colored(\"üî¥ High\", \"red\")\n",
    "        if value < thresholds[1]: return colored(\"üü° Moderate\", \"yellow\")\n",
    "        return colored(\"üü¢ Low\", \"green\")\n",
    "    else:        # larger is worse\n",
    "        if value > thresholds[1]: return colored(\"üî¥ High\", \"red\")\n",
    "        if value > thresholds[0]: return colored(\"üü° Moderate\", \"yellow\")\n",
    "        return colored(\"üü¢ Low\", \"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa41e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Pretty print diagnostic report\n",
    "# ================================================================\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"METADATA DEPENDENCY & DOMAIN BIAS REPORT (AUTO)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Patient overlap\n",
    "print(\"Patient overlap check:\")\n",
    "if overlap_pids:\n",
    "    print(f\"  üî¥ {len(overlap_pids)} patients appear in both splits ‚Üí leakage risk!\")\n",
    "    print(f\"  PIDs: {', '.join(map(str, overlap_pids))}\")\n",
    "else:\n",
    "    print(\"  üü¢ No patient overlap detected (clean split).\")\n",
    "\n",
    "# Chi-square associations\n",
    "print(\"\\nVariable Associations (œá¬≤ tests):\")\n",
    "for name, vals in chi_results.items():\n",
    "    p = vals[\"p\"]\n",
    "    significance = \"üî¥ Significant\" if p < 0.001 else \"üü° Weak\"\n",
    "    print(f\"  ‚Ä¢ {name:<25} œá¬≤={vals['chi2']:>7.2f} (dof={vals['dof']})  p={p:.4f} ‚Üí {significance}\")\n",
    "print(\"    ‚Üí All metadata factors are statistically coupled with labels, indicating domain bias.\\n\")\n",
    "\n",
    "# Leakage metrics\n",
    "print(\"Metadata predictability tests:\")\n",
    "print(f\"  - Predicting Device from Label: acc={scores_dev_acc.mean():.3f}, \"\n",
    "      f\"F1-macro={scores_dev_f1.mean():.3f} ‚Üí {color_flag(scores_dev_acc.mean(), (0.4, 0.5))} confounding\")\n",
    "print(f\"  - Predicting Label from Metadata: acc={scores_lbl_acc.mean():.3f}, \"\n",
    "      f\"F1-macro={scores_lbl_f1.mean():.3f} ‚Üí {color_flag(scores_lbl_acc.mean(), (0.35, 0.45))} confounding\")\n",
    "print(\"    ‚Üí Metadata alone explains substantial variance in labels ‚Äî strong device/site correlation.\\n\")\n",
    "\n",
    "# KL divergence\n",
    "print(f\"KL Divergence (Train‚ÜíTest label distributions): {kl:.3f} ‚Üí {color_flag(kl, (0.02, 0.05))}\")\n",
    "print(\"    ‚Üí Indicates mild domain drift between training and test label compositions.\\n\")\n",
    "\n",
    "# Coverage & entropy\n",
    "print(\"Coverage & diversity:\")\n",
    "print(f\"  - Missing label combinations per (Device, Site): {missing_sites}\")\n",
    "print(f\"  - Mean recording entropy: {entropy_mean:.2f} (0=pure, >0=mixed)\")\n",
    "print(f\"  - % of pure-label recordings: {entropy_pure*100:.1f}%\")\n",
    "print(\"    ‚Üí Mixed recordings indicate intra-patient label heterogeneity (multi-label or temporal variability).\\n\")\n",
    "\n",
    "# Cycle duration drift summary\n",
    "dur = df.groupby(\"label_4c\")[\"CycleDur\"].describe()\n",
    "print(\"Cycle duration drift:\")\n",
    "for lbl, row in dur.iterrows():\n",
    "    print(f\"  - {lbl:<8}: mean={row['mean']:.2f}s | median={row['50%']:.2f}s | max={row['max']:.2f}s\")\n",
    "print(\"    ‚Üí Abnormal cycles (Crackle/Both) slightly longer (~2.8‚Äì3.1s).\")\n",
    "print(\"      Train‚Äìtest difference in Crackle duration hints at annotation drift.\\n\")\n",
    "\n",
    "# Device‚Äìsite coverage overview\n",
    "device_counts = df[\"Device\"].value_counts(normalize=True).round(3).to_dict()\n",
    "print(\"Device‚ÄìSite coverage:\")\n",
    "print(f\"  - Device proportions: {device_counts}\")\n",
    "print(\"  - Dominant device: AKGC417L (>50%)\")\n",
    "print(\"  - LittC2SE absent in test ‚Üí unseen domain for that hardware.\")\n",
    "print(\"  - Posterior sites (Pl, Pr, Ll, Lr) more crackle-heavy; Trachea mostly Normal (~70%).\\n\")\n",
    "\n",
    "# Final risk summary\n",
    "print(\"=\"*100)\n",
    "print(\" RISK ASSESSMENT SUMMARY\")\n",
    "print(\"=\"*100)\n",
    "risk_summary = [\n",
    "    (\"Device/Site confounding\", \"High\"),\n",
    "    (\"Patient overlap\", \"High\" if overlap_pids else \"Low\"),\n",
    "    (\"Split drift (KL)\", \"Moderate\" if kl > 0.02 else \"Low\"),\n",
    "    (\"Intra-patient variability\", \"Moderate\" if entropy_mean > 0.2 else \"Low\"),\n",
    "    (\"Class balance\", \"Low\")\n",
    "]\n",
    "for r, lvl in risk_summary:\n",
    "    icon = {\"High\":\"üü•\",\"Moderate\":\"üüß\",\"Low\":\"üü©\"}[lvl]\n",
    "    print(f\"  {icon} {r:<30} {lvl}\")\n",
    "\n",
    "# Recommendations\n",
    "print(\"\\nACTIONABLE RECOMMENDATIONS:\")\n",
    "print(\"  1. Rebuild patient-wise split ensuring no overlap (leakage-free).\")\n",
    "print(\"  2. Stratify folds by Device & AuscLoc to preserve proportions.\")\n",
    "print(\"  3. During training:\")\n",
    "print(\"       ‚Ä¢ Include Device & Site as conditioning or adversarial inputs.\")\n",
    "print(\"       ‚Ä¢ Log per-device & per-site F1-macro metrics.\")\n",
    "print(\"       ‚Ä¢ Use EQ jitter, SpecAugment, loudness norm for domain robustness.\")\n",
    "print(\"  4. During evaluation:\")\n",
    "print(\"       ‚Ä¢ Report per-domain (device/site) breakdowns.\")\n",
    "print(\"       ‚Ä¢ Use macro-F1 and per-class AUROC for fair reporting.\")\n",
    "print(\"  5. Consider leave-one-device-out CV for true generalization.\\n\")\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"END OF METADATA DIAGNOSTIC REPORT\")\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcab4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency = pd.crosstab(df[\"AuscLoc\"], df[\"label_4c\"])\n",
    "chi2, p, dof, expected = chi2_contingency(contingency)\n",
    "\n",
    "residuals = (contingency - expected) / np.sqrt(expected)\n",
    "residuals_rounded = residuals.round(2)\n",
    "\n",
    "print(f\"Chi¬≤ = {chi2:.2f}, p = {p:.5f}\")\n",
    "print(\"\\nStandardized residuals (positive = over-represented):\")\n",
    "print(residuals_rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a369a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "def MI(a,b): return mutual_info_score(a,b)\n",
    "\n",
    "print(\"Mutual Information (bits):\")\n",
    "print(f\"  Device‚ÄìLabel_4c: {MI(df['Device'], df['label_4c']):.3f}\")\n",
    "print(f\"  AuscLoc‚ÄìLabel_4c: {MI(df['AuscLoc'], df['label_4c']):.3f}\")\n",
    "print(f\"  Split‚ÄìLabel_4c: {MI(df['Split'], df['label_4c']):.3f}\")\n",
    "print(f\"  Device‚ÄìAuscLoc: {MI(df['Device'], df['AuscLoc']):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e82975c",
   "metadata": {},
   "source": [
    "Global null hypothesis. \n",
    "\n",
    "H‚ÇÄ (global): The distribution of label_4c is independent of auscultation site.  \n",
    "H‚ÇÅ (global): The distribution of label_4c differs across auscultation sites.  \n",
    "\n",
    "‚Üí Test: Chi-square test of independence. \n",
    "‚Üí If p < 0.05 ‚Üí reject H‚ÇÄ ‚Üí there is a site‚Äìlabel association.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64ce069",
   "metadata": {},
   "source": [
    "For each site s and class c:\n",
    "\n",
    "H‚ÇÄ(s,c): The probability of observing class c at site s is equal to the overall probability of class c in the dataset.  \n",
    "H‚ÇÅ(s,c): The probability of observing class c at site s differs from the overall class proportion.  \n",
    "\n",
    "‚Üí Test: Binomial proportion test or standardized residuals from œá¬≤ (which are equivalent asymptotically).  \n",
    "‚Üí Bonferroni or FDR-corrected p-values handle multiple comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea0f7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency, norm\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# Contingency table\n",
    "ct = pd.crosstab(df[\"AuscLoc\"], df[\"label_4c\"])\n",
    "\n",
    "# 1. Global test\n",
    "chi2, p_global, dof, expected = chi2_contingency(ct)\n",
    "print(f\"Global œá¬≤ = {chi2:.2f}, p = {p_global:.6f} ‚Üí {'Reject H‚ÇÄ' if p_global < 0.05 else 'Fail to reject H‚ÇÄ'}\")\n",
    "\n",
    "# 2. Post-hoc residual analysis\n",
    "residuals = (ct - expected) / np.sqrt(expected)\n",
    "z_scores = residuals.values.flatten()\n",
    "pvals = 2 * (1 - norm.cdf(np.abs(z_scores)))  # two-tailed p-values\n",
    "pvals_corrected = multipletests(pvals, method=\"fdr_bh\")[1]  # FDR correction\n",
    "\n",
    "# Put results back in dataframe\n",
    "posthoc_df = pd.DataFrame({\n",
    "    \"AuscLoc\": np.repeat(ct.index, ct.shape[1]),\n",
    "    \"Label\": np.tile(ct.columns, len(ct.index)),\n",
    "    \"z\": z_scores,\n",
    "    \"p_uncorrected\": pvals,\n",
    "    \"p_corrected\": pvals_corrected\n",
    "})\n",
    "posthoc_df[\"signif\"] = posthoc_df[\"p_corrected\"] < 0.05\n",
    "display(posthoc_df.sort_values(\"p_corrected\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e446ac",
   "metadata": {},
   "source": [
    "You can interpret each (site, class) pair like this:  \n",
    "* z > +2, p < 0.05 ‚Üí class over-represented at that site.  \n",
    "* z < ‚àí2, p < 0.05 ‚Üí class under-represented at that site. \n",
    "\n",
    "This yields an anatomical map of where each abnormality tends to appear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae783c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "z_mat = residuals.copy()\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.heatmap(z_mat, annot=True, center=0, cmap=\"coolwarm\", fmt=\".1f\")\n",
    "plt.title(\"Standardized Residuals (Z-scores) ‚Äî AuscLoc √ó Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4738e7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = (\n",
    "    posthoc_df.query(\"signif\")\n",
    "    .groupby(\"AuscLoc\")[\"Label\"]\n",
    "    .apply(list)\n",
    "    .reset_index()\n",
    ")\n",
    "summary.columns = [\"AuscLoc\", \"SignificantOverrepresentedLabels\"]\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e7a0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kruskal\n",
    "\n",
    "# Kruskal-Wallis test for CycleDur across 4-class labels\n",
    "groups = [df.loc[df[\"label_4c\"] == lbl, \"CycleDur\"] for lbl in df[\"label_4c\"].unique()]\n",
    "\n",
    "stat, p = kruskal(*groups)\n",
    "print(f\"Kruskal-Wallis H-statistic: {stat:.2f}, p-value: {p:.6f} ‚Üí {'Reject H‚ÇÄ' if p < 0.05 else 'Fail to reject H‚ÇÄ'}\")\n",
    "if p < 0.05:\n",
    "    print(\"Significant differences in CycleDur distributions across labels.\")\n",
    "else:\n",
    "    print(\"No significant differences in CycleDur distributions across labels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1124760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikit_posthocs import posthoc_dunn\n",
    "\n",
    "# Perform pairwise Dunn test with Bonferroni correction\n",
    "posthoc = posthoc_dunn(df, val_col=\"CycleDur\", group_col=\"label_4c\", p_adjust=\"bonferroni\")\n",
    "print(posthoc.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b35e093",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.assign(\n",
    "    Sex=(df[\"Sex\"]==\"M\").astype(int),\n",
    "    Split=(df[\"Split\"]==\"train\").astype(int),\n",
    ").select_dtypes(\"number\").corr()\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "sns.heatmap(corr, annot=True, cmap=\"coolwarm\", center=0)\n",
    "plt.title(\"Metadata feature correlation matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3546c532",
   "metadata": {},
   "source": [
    "### No significant correlations found instead the trivial ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9710ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from patsy import dmatrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6f929e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Preprocessing\n",
    "# ------------------------------------------------\n",
    "df_demo = df.copy()\n",
    "df_demo = df_demo[df_demo[\"Age\"].notna()]\n",
    "df_demo = df_demo[df_demo[\"BMI\"].notna()]\n",
    "df_demo[\"Sex\"] = df_demo[\"Sex\"].astype(str)\n",
    "\n",
    "print(\"=\"*90)\n",
    "print(\" DEMOGRAPHIC BIAS ANALYSIS (Age, Sex, BMI)\".center(90))\n",
    "print(\"=\"*90, \"\\n\")\n",
    "\n",
    "# ================================================================\n",
    "# AGE vs LABEL\n",
    "# ================================================================\n",
    "groups = [df_demo.loc[df_demo[\"label_4c\"] == l, \"Age\"] for l in df_demo[\"label_4c\"].unique()]\n",
    "stat, p = kruskal(*groups)\n",
    "print(\"AGE vs LABEL\")\n",
    "print(f\"  Kruskal‚ÄìWallis H-statistic: {stat:.2f}, p-value: {p:.6f}\")\n",
    "if p < 0.05:\n",
    "    print(\"  üî¥ Reject H‚ÇÄ ‚Üí Significant age differences across labels.\")\n",
    "else:\n",
    "    print(\"  üü¢ Fail to reject H‚ÇÄ ‚Üí No significant age differences.\\n\")\n",
    "\n",
    "# Post-hoc Dunn test\n",
    "posthoc_age = posthoc_dunn(df_demo, val_col=\"Age\", group_col=\"label_4c\", p_adjust=\"bonferroni\")\n",
    "print(\"  Post-hoc Dunn‚Äôs test (adjusted p-values):\")\n",
    "print(\"if p < 0.05, significant difference between groups\")\n",
    "print(posthoc_age.round(4))\n",
    "print()\n",
    "\n",
    "# Visualization\n",
    "sns.boxplot(data=df_demo, x=\"label_4c\", y=\"Age\", palette=\"Set2\")\n",
    "plt.title(\"Age distribution across 4-class labels\")\n",
    "plt.show()\n",
    "\n",
    "# ================================================================\n",
    "# SEX vs LABEL\n",
    "# ================================================================\n",
    "ct_sex = pd.crosstab(df_demo[\"Sex\"], df_demo[\"label_4c\"])\n",
    "chi2, p, dof, exp = chi2_contingency(ct_sex)\n",
    "print(\"=\"*90)\n",
    "print(\" SEX vs LABEL\")\n",
    "print(\"=\"*90)\n",
    "print(f\"  œá¬≤ = {chi2:.2f}, p-value = {p:.6f}\")\n",
    "if p < 0.05:\n",
    "    print(\"  üî¥ Reject H‚ÇÄ ‚Üí Sex and label are dependent (imbalanced gender distribution across labels).\")\n",
    "else:\n",
    "    print(\"  üü¢ Fail to reject H‚ÇÄ ‚Üí No significant sex imbalance.\\n\")\n",
    "\n",
    "print(\"\\n  Sex √ó Label contingency table:\")\n",
    "display(ct_sex)\n",
    "\n",
    "sns.heatmap(ct_sex, annot=True, fmt=\"d\", cmap=\"YlGnBu\")\n",
    "plt.title(\"Sex √ó Label counts\")\n",
    "plt.show()\n",
    "\n",
    "# ================================================================\n",
    "# BMI vs LABEL\n",
    "# ================================================================\n",
    "groups_bmi = [df_demo.loc[df_demo[\"label_4c\"] == l, \"BMI\"] for l in df_demo[\"label_4c\"].unique()]\n",
    "stat, p = kruskal(*groups_bmi)\n",
    "print(\"=\"*90)\n",
    "print(\"  BMI vs LABEL\")\n",
    "print(\"=\"*90)\n",
    "print(f\"  Kruskal‚ÄìWallis H-statistic: {stat:.2f}, p-value: {p:.6f}\")\n",
    "if p < 0.05:\n",
    "    print(\"  üî¥ Reject H‚ÇÄ ‚Üí Significant BMI differences across labels.\")\n",
    "else:\n",
    "    print(\"  üü¢ Fail to reject H‚ÇÄ ‚Üí No significant BMI differences.\\n\")\n",
    "\n",
    "# Post-hoc Dunn test for BMI\n",
    "posthoc_bmi = posthoc_dunn(df_demo, val_col=\"BMI\", group_col=\"label_4c\", p_adjust=\"bonferroni\")\n",
    "print(\"  Post-hoc Dunn‚Äôs test (adjusted p-values):\")\n",
    "print(posthoc_bmi.round(4))\n",
    "print()\n",
    "\n",
    "# Visualization\n",
    "sns.boxplot(data=df_demo, x=\"label_4c\", y=\"BMI\", palette=\"Set2\")\n",
    "plt.title(\"BMI distribution across 4-class labels\")\n",
    "plt.show()\n",
    "\n",
    "# ================================================================\n",
    "# LOGISTIC MODEL ‚Äî Combined demographic predictors\n",
    "# ================================================================\n",
    "print(\"=\"*90)\n",
    "print(\" Logistic model ‚Äî Predicting abnormality (Normal vs Abnormal) from demographics\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "df_demo[\"is_abnormal\"] = (df_demo[\"label_2c\"] == \"Abnormal\").astype(int)\n",
    "y, X = dmatrices(\"is_abnormal ~ Age + BMI + C(Sex)\", data=df_demo, return_type=\"dataframe\")\n",
    "\n",
    "model = sm.Logit(y, X).fit(disp=False)\n",
    "odds_ratios = np.exp(model.params).round(3)\n",
    "print(model.summary())\n",
    "print(\"\\n  Odds Ratios:\")\n",
    "print(odds_ratios)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca9b223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# üß≠ AUTOMATED INTERPRETIVE SUMMARY\n",
    "# ================================================================\n",
    "print(\"=\"*90)\n",
    "print(\"üìñ DEMOGRAPHIC BIAS ‚Äî INTERPRETIVE SUMMARY\".center(90))\n",
    "print(\"=\"*90)\n",
    "\n",
    "summary_lines = []\n",
    "\n",
    "# 1. Age effect\n",
    "if model.pvalues[\"Age\"] < 0.05:\n",
    "    if model.params[\"Age\"] > 0:\n",
    "        summary_lines.append(f\"‚Ä¢ üî∫ Age is a significant positive predictor (p={model.pvalues['Age']:.3e}) ‚Äî \"\n",
    "                             f\"older patients are more likely to exhibit abnormal sounds \"\n",
    "                             f\"(OR={odds_ratios['Age']:.3f}).\")\n",
    "    else:\n",
    "        summary_lines.append(f\"‚Ä¢ üîª Age is a significant negative predictor ‚Äî \"\n",
    "                             f\"younger patients are more likely abnormal (OR={odds_ratios['Age']:.3f}).\")\n",
    "else:\n",
    "    summary_lines.append(\"‚Ä¢ üü¢ No significant age effect detected (p‚â•0.05).\")\n",
    "\n",
    "# 2. BMI effect\n",
    "if model.pvalues[\"BMI\"] < 0.05:\n",
    "    if model.params[\"BMI\"] > 0:\n",
    "        summary_lines.append(f\"‚Ä¢ ‚öñÔ∏è Higher BMI increases abnormality likelihood (OR={odds_ratios['BMI']:.3f}).\")\n",
    "    else:\n",
    "        summary_lines.append(f\"‚Ä¢ ‚öñÔ∏è Higher BMI decreases abnormality likelihood (p={model.pvalues['BMI']:.3e}) ‚Äî \"\n",
    "                             f\"leaner individuals show more abnormal cycles (OR={odds_ratios['BMI']:.3f}).\")\n",
    "else:\n",
    "    summary_lines.append(\"‚Ä¢ üü¢ No significant BMI effect detected.\")\n",
    "\n",
    "# 3. Sex effect\n",
    "sex_p = model.pvalues.get(\"C(Sex)[T.M]\", np.nan)\n",
    "sex_coef = model.params.get(\"C(Sex)[T.M]\", 0)\n",
    "if sex_p < 0.05:\n",
    "    if sex_coef > 0:\n",
    "        summary_lines.append(f\"‚Ä¢ ‚öß Males more likely to produce abnormal cycles (OR={odds_ratios['C(Sex)[T.M]']:.3f}).\")\n",
    "    else:\n",
    "        summary_lines.append(f\"‚Ä¢ ‚öß Females more likely to produce abnormal cycles (OR={odds_ratios['C(Sex)[T.M]']:.3f}).\")\n",
    "else:\n",
    "    summary_lines.append(\"‚Ä¢ üü¢ No significant sex difference observed (p‚â•0.05).\")\n",
    "\n",
    "# 4. Model goodness\n",
    "r2 = model.prsquared\n",
    "llr_p = model.llr_pvalue\n",
    "summary_lines.append(f\"‚Ä¢ Model pseudo-R¬≤={r2:.3f}, global p={llr_p:.3e} ‚Üí overall demographic effects are statistically significant.\")\n",
    "\n",
    "# Print intuitive conclusions\n",
    "for line in summary_lines:\n",
    "    print(\" \", line)\n",
    "\n",
    "print(\"\\nüìå Suggested interpretation:\")\n",
    "if (model.pvalues[\"Age\"] < 0.05) and (model.params[\"Age\"] > 0):\n",
    "    print(\"   ‚Üí Abnormal sounds are more frequent among older individuals, possibly reflecting age-related respiratory changes.\")\n",
    "if (model.pvalues[\"BMI\"] < 0.05) and (model.params[\"BMI\"] < 0):\n",
    "    print(\"   ‚Üí Leaner subjects may exhibit clearer crackle/wheeze patterns due to thinner chest walls (less attenuation).\")\n",
    "if sex_p >= 0.05:\n",
    "    print(\"   ‚Üí No gender-driven acoustic differences detected; male/female balance is adequate.\")\n",
    "print(\"   ‚Üí Demographic effects exist but explain modest variance (pseudo-R¬≤‚âà0.04). Consider age/BMI-aware sampling or include demographics as auxiliary inputs.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b32000d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icbhi-ast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
