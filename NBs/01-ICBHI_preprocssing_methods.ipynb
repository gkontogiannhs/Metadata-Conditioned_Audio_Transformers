{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d2783e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import scipy.signal as signal\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2033de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_with_heartbeat_path = \"/home/AIoT04/Datasets/icbhi_dataset/101_1b1_Al_sc_Meditron.wav\"\n",
    "cough_with_voice_path = \"/home/AIoT04/Datasets/icbhi_dataset/218_1b1_Pl_sc_Meditron.wav\"\n",
    "medical_device_sound_path = \"/home/AIoT04/Datasets/icbhi_dataset/207_2b3_Ar_mc_AKGC417L.wav\"\n",
    "clock_like_sound_path = \"/home/AIoT04/Datasets/icbhi_dataset/107_2b3_Lr_mc_AKGC417L.wav\"\n",
    "whistle_like_sound_path = \"/home/AIoT04/Datasets/icbhi_dataset/107_2b4_Ll_mc_AKGC417L.wav\"\n",
    "horn_like_sound_path = \"/home/AIoT04/Datasets/icbhi_dataset/147_2b3_Lr_mc_AKGC417L.wav\"\n",
    "stationary_noise_path = \"/home/AIoT04/Datasets/icbhi_dataset/204_2b5_Ar_mc_AKGC417L.wav\"\n",
    "mic_peak_path = \"/home/AIoT04/Datasets/icbhi_dataset/213_1p5_Tc_mc_AKGC417L.wav\"\n",
    "miss_classified_crackles_path = \"/home/AIoT04/Datasets/icbhi_dataset/213_2p2_Pr_mc_AKGC417L.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bc2f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 160000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be842adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_with_heartbeat = librosa.load(ls_with_heartbeat_path, sr=SAMPLE_RATE)[0]\n",
    "cough_with_voice = librosa.load(cough_with_voice_path, sr=SAMPLE_RATE)[0]\n",
    "medical_device_sound = librosa.load(medical_device_sound_path, sr=SAMPLE_RATE)[0]\n",
    "clock_like_sound = librosa.load(clock_like_sound_path, sr=SAMPLE_RATE)[0]\n",
    "whistle_like_sound = librosa.load(whistle_like_sound_path, sr=SAMPLE_RATE)[0]\n",
    "horn_like_sound = librosa.load(horn_like_sound_path, sr=SAMPLE_RATE)[0]\n",
    "stationary_noise = librosa.load(stationary_noise_path, sr=SAMPLE_RATE)[0]\n",
    "mic_peak = librosa.load(mic_peak_path, sr=SAMPLE_RATE)[0]\n",
    "miss_classified_crackles = librosa.load(miss_classified_crackles_path, sr=SAMPLE_RATE)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40756831",
   "metadata": {},
   "source": [
    "## Stationary noise removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10863f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(stationary_noise, rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa18dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stationary_noise(audio, threshold_db=3, frame_length=2048):\n",
    "    \"\"\"\n",
    "    Remove stationary noise using spectral gating.\n",
    "    \n",
    "    Strategy:\n",
    "    - Extract spectrogram\n",
    "    - Compute noise profile from quiet frames\n",
    "    - Apply spectral subtraction\n",
    "    - Handles: white noise, bzzzz, background hum\n",
    "    \n",
    "    Args:\n",
    "        audio: waveform\n",
    "        threshold_db: noise floor in dB (relative to max)\n",
    "        frame_length: FFT frame length\n",
    "    \n",
    "    Returns:\n",
    "        Noise-reduced audio\n",
    "    \"\"\"\n",
    "    # STFT\n",
    "    D = librosa.stft(audio, n_fft=frame_length, hop_length=frame_length//4)\n",
    "    magnitude = np.abs(D)\n",
    "    phase = np.angle(D)\n",
    "    \n",
    "    # Convert to dB\n",
    "    S_db = librosa.power_to_db(magnitude**2, ref=np.max(magnitude**2))\n",
    "    \n",
    "    # Estimate noise profile from quiet frames (bottom 10%)\n",
    "    noise_floor = np.percentile(S_db, 10, axis=1, keepdims=True)\n",
    "    \n",
    "    # Spectral subtraction\n",
    "    S_db_denoised = S_db - noise_floor\n",
    "    S_db_denoised = np.maximum(S_db_denoised, threshold_db)  # Floor at -40dB\n",
    "    \n",
    "    # Convert back to linear\n",
    "    magnitude_denoised = librosa.db_to_power(S_db_denoised) ** 0.5\n",
    "    \n",
    "    # Reconstruct\n",
    "    D_denoised = magnitude_denoised * np.exp(1j * phase)\n",
    "    audio_denoised = librosa.istft(D_denoised, hop_length=frame_length//4)\n",
    "    \n",
    "    return audio_denoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25ddff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "staionary_denoised = remove_stationary_noise(stationary_noise, frame_length=512)\n",
    "ipd.Audio(staionary_denoised, rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c854233",
   "metadata": {},
   "source": [
    "### using noisereduce lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371f123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import noisereduce as nr\n",
    "\n",
    "# perform noise reduction\n",
    "reduced_noise = nr.reduce_noise(y=mic_peak, sr=SAMPLE_RATE, stationary=True)\n",
    "ipd.Audio(reduced_noise, rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b174c73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ICBHINoiseRobustPreprocessor:\n",
    "    \"\"\"\n",
    "    Comprehensive preprocessing pipeline for ICBHI 2017 dataset.\n",
    "    Addresses: heart sounds, stationary noise, coughs, birds, speech.\n",
    "    \n",
    "    Publication-ready with detailed documentation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, sr=16000, n_mels=128, n_fft=512, hop_length=160):\n",
    "        self.sr = sr\n",
    "        self.n_mels = n_mels\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "    \n",
    "    \n",
    "    # ============================================================\n",
    "    # 2. STATIONARY NOISE REMOVAL (Spectral Gating)\n",
    "    # ============================================================\n",
    "\n",
    "    \n",
    "    # ============================================================\n",
    "    # 3. COUGH DETECTION & REMOVAL\n",
    "    # ============================================================\n",
    "    def detect_coughs(self, audio, threshold_percentile=85, min_duration=0.1):\n",
    "        \"\"\"\n",
    "        Detect cough sounds using energy and spectral characteristics.\n",
    "        \n",
    "        Cough characteristics:\n",
    "        - High energy bursts\n",
    "        - Broad spectrum (different from tonal wheezes)\n",
    "        - Transient (short duration peaks)\n",
    "        \n",
    "        Args:\n",
    "            audio: waveform\n",
    "            threshold_percentile: energy threshold for detection\n",
    "            min_duration: minimum duration in seconds\n",
    "        \n",
    "        Returns:\n",
    "            cough_mask: binary mask (True = cough)\n",
    "            cough_segments: list of (start, end) frames\n",
    "        \"\"\"\n",
    "        # Compute frame energy\n",
    "        frame_length = 512\n",
    "        hop_length = 160\n",
    "        \n",
    "        frames = librosa.util.frame(audio, frame_length=frame_length, \n",
    "                                    hop_length=hop_length)\n",
    "        energy = np.sqrt(np.sum(frames**2, axis=0))\n",
    "        energy_normalized = (energy - np.mean(energy)) / (np.std(energy) + 1e-8)\n",
    "        \n",
    "        # Threshold\n",
    "        threshold = np.percentile(energy_normalized, threshold_percentile)\n",
    "        cough_frames = energy_normalized > threshold\n",
    "        \n",
    "        # Post-processing: remove isolated peaks\n",
    "        min_frames = int(min_duration * self.sr / hop_length)\n",
    "        cough_mask = ndimage.binary_closing(cough_frames, \n",
    "                                           structure=np.ones(min_frames//2))\n",
    "        cough_mask = ndimage.binary_opening(cough_mask,\n",
    "                                           structure=np.ones(min_frames//4))\n",
    "        \n",
    "        # Find segments\n",
    "        changes = np.diff(cough_mask.astype(int))\n",
    "        starts = np.where(changes == 1)[0]\n",
    "        ends = np.where(changes == -1)[0]\n",
    "        \n",
    "        segments = list(zip(starts, ends))\n",
    "        \n",
    "        return cough_mask, segments\n",
    "    \n",
    "    def remove_coughs(self, audio, cough_segments, method='interpolate'):\n",
    "        \"\"\"\n",
    "        Remove detected cough segments.\n",
    "        \n",
    "        Methods:\n",
    "        - 'silence': Replace with zero\n",
    "        - 'interpolate': Smooth interpolation (preserves continuity)\n",
    "        - 'mute': Reduce amplitude by 50%\n",
    "        \n",
    "        Args:\n",
    "            audio: waveform\n",
    "            cough_segments: list of (start_frame, end_frame)\n",
    "            method: removal method\n",
    "        \n",
    "        Returns:\n",
    "            Cough-reduced audio\n",
    "        \"\"\"\n",
    "        audio_processed = audio.copy()\n",
    "        hop_length = 160\n",
    "        \n",
    "        for start_frame, end_frame in cough_segments:\n",
    "            start_sample = start_frame * hop_length\n",
    "            end_sample = end_frame * hop_length\n",
    "            \n",
    "            if method == 'silence':\n",
    "                audio_processed[start_sample:end_sample] = 0\n",
    "            \n",
    "            elif method == 'interpolate':\n",
    "                # Smooth interpolation between boundaries\n",
    "                if start_sample > 0 and end_sample < len(audio_processed):\n",
    "                    start_val = audio_processed[start_sample - 1]\n",
    "                    end_val = audio_processed[end_sample]\n",
    "                    length = end_sample - start_sample\n",
    "                    interpolated = np.linspace(start_val, end_val, length)\n",
    "                    audio_processed[start_sample:end_sample] = interpolated\n",
    "            \n",
    "            elif method == 'mute':\n",
    "                audio_processed[start_sample:end_sample] *= 0.3\n",
    "        \n",
    "        return audio_processed\n",
    "    \n",
    "    # ============================================================\n",
    "    # 4. SPEECH & BIRD DETECTION (Spectral Shape Analysis)\n",
    "    # ============================================================\n",
    "    def detect_anomalous_sounds(self, audio, window_size=2048, hop_length=512):\n",
    "        \"\"\"\n",
    "        Detect speech/bird sounds using spectral characteristics.\n",
    "        \n",
    "        Strategy:\n",
    "        - Speech: Formant patterns, specific spectral peaks\n",
    "        - Birds: Rapid frequency modulation, higher frequencies\n",
    "        - Lung sounds: More uniform spectral distribution\n",
    "        \n",
    "        Args:\n",
    "            audio: waveform\n",
    "            window_size: analysis window\n",
    "            hop_length: hop length\n",
    "        \n",
    "        Returns:\n",
    "            anomaly_mask: binary mask of detected anomalies\n",
    "            anomaly_score: confidence scores\n",
    "        \"\"\"\n",
    "        # Compute spectrogram\n",
    "        D = librosa.stft(audio, n_fft=window_size, hop_length=hop_length)\n",
    "        S = np.abs(D) ** 2\n",
    "        S_db = librosa.power_to_db(S, ref=np.max(S))\n",
    "        \n",
    "        # Feature 1: Spectral Centroid (high = speech/birds)\n",
    "        centroid = librosa.feature.spectral_centroid(S=S)[0]\n",
    "        centroid_norm = (centroid - np.mean(centroid)) / (np.std(centroid) + 1e-8)\n",
    "        \n",
    "        # Feature 2: Spectral Flatness (low = tonal speech, high = noisy lung sounds)\n",
    "        flatness = librosa.feature.spectral_flatness(S=S)[0]\n",
    "        flatness_norm = (flatness - np.mean(flatness)) / (np.std(flatness) + 1e-8)\n",
    "        \n",
    "        # Feature 3: Zero Crossing Rate (high = speech, low = smooth lung sounds)\n",
    "        zcr = librosa.feature.zero_crossing_rate(audio, hop_length=hop_length)[0]\n",
    "        zcr_norm = (zcr - np.mean(zcr)) / (np.std(zcr) + 1e-8)\n",
    "        \n",
    "        # Combine features\n",
    "        # Speech/Birds: high centroid + high zcr + low flatness\n",
    "        anomaly_score = (centroid_norm + zcr_norm - flatness_norm) / 3\n",
    "        anomaly_score = (anomaly_score - np.mean(anomaly_score)) / (np.std(anomaly_score) + 1e-8)\n",
    "        \n",
    "        # Threshold\n",
    "        threshold = np.percentile(anomaly_score, 75)\n",
    "        anomaly_mask = anomaly_score > threshold\n",
    "        \n",
    "        return anomaly_mask, anomaly_score\n",
    "    \n",
    "    def apply_spectral_masking(self, audio, anomaly_mask, hop_length=512, \n",
    "                               method='soft_mask', attenuation_db=-20):\n",
    "        \"\"\"\n",
    "        Apply spectral masking to anomalous regions.\n",
    "        \n",
    "        Args:\n",
    "            audio: waveform\n",
    "            anomaly_mask: binary mask from detect_anomalous_sounds\n",
    "            method: 'soft_mask' (reduce) or 'hard_mask' (remove)\n",
    "            attenuation_db: how much to reduce anomalous regions\n",
    "        \n",
    "        Returns:\n",
    "            Masked audio\n",
    "        \"\"\"\n",
    "        # Convert mask to frequency domain\n",
    "        D = librosa.stft(audio, n_fft=512, hop_length=hop_length)\n",
    "        magnitude = np.abs(D)\n",
    "        phase = np.angle(D)\n",
    "        \n",
    "        if method == 'soft_mask':\n",
    "            # Soft masking - reduce anomalous frames\n",
    "            attenuation = 10 ** (attenuation_db / 20)\n",
    "            for t_idx, is_anomaly in enumerate(anomaly_mask):\n",
    "                if is_anomaly:\n",
    "                    magnitude[:, t_idx] *= attenuation\n",
    "        \n",
    "        elif method == 'hard_mask':\n",
    "            # Hard masking - remove anomalous frames\n",
    "            magnitude[:, anomaly_mask] = 0\n",
    "        \n",
    "        D_masked = magnitude * np.exp(1j * phase)\n",
    "        audio_masked = librosa.istft(D_masked, hop_length=hop_length)\n",
    "        \n",
    "        return audio_masked\n",
    "    \n",
    "    # ============================================================\n",
    "    # 5. COMPLETE PIPELINE\n",
    "    # ============================================================\n",
    "    def preprocess(self, audio, apply_heart_removal=True, \n",
    "                   apply_noise_removal=True, apply_cough_removal=True,\n",
    "                   apply_anomaly_masking=True, verbose=True):\n",
    "        \"\"\"\n",
    "        Complete preprocessing pipeline.\n",
    "        \n",
    "        Recommended for publication:\n",
    "        1. Heart sound removal\n",
    "        2. Stationary noise removal\n",
    "        3. Cough detection & removal\n",
    "        4. Speech/bird anomaly masking\n",
    "        \"\"\"\n",
    "        audio_processed = audio.copy()\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"=\" * 60)\n",
    "            print(\"ICBHI PREPROCESSING PIPELINE\")\n",
    "            print(\"=\" * 60)\n",
    "        \n",
    "        # Step 1: Heart sound removal\n",
    "        if apply_heart_removal:\n",
    "            audio_processed = self.remove_heart_sounds(audio_processed, cutoff_hz=2000)\n",
    "            if verbose:\n",
    "                print(\"✓ Heart sound removal (HP filter @ 2000Hz)\")\n",
    "        \n",
    "        # Step 2: Stationary noise removal\n",
    "        if apply_noise_removal:\n",
    "            audio_processed = self.remove_stationary_noise(audio_processed, \n",
    "                                                          threshold_db=-40)\n",
    "            if verbose:\n",
    "                print(\"✓ Stationary noise removal (spectral subtraction)\")\n",
    "        \n",
    "        # Step 3: Cough detection and removal\n",
    "        if apply_cough_removal:\n",
    "            cough_mask, cough_segments = self.detect_coughs(audio_processed)\n",
    "            audio_processed = self.remove_coughs(audio_processed, cough_segments,\n",
    "                                                method='interpolate')\n",
    "            if verbose:\n",
    "                print(f\"✓ Cough removal ({len(cough_segments)} segments detected)\")\n",
    "        \n",
    "        # Step 4: Speech/bird anomaly masking\n",
    "        if apply_anomaly_masking:\n",
    "            anomaly_mask, scores = self.detect_anomalous_sounds(audio_processed)\n",
    "            audio_processed = self.apply_spectral_masking(audio_processed, \n",
    "                                                         anomaly_mask,\n",
    "                                                         method='soft_mask',\n",
    "                                                         attenuation_db=-20)\n",
    "            if verbose:\n",
    "                pct_anomalous = 100 * np.sum(anomaly_mask) / len(anomaly_mask)\n",
    "                print(f\"✓ Anomaly masking ({pct_anomalous:.1f}% flagged)\")\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"=\" * 60)\n",
    "        \n",
    "        return audio_processed\n",
    "    \n",
    "    # ============================================================\n",
    "    # 6. VISUALIZATION & QUALITY CONTROL\n",
    "    # ============================================================\n",
    "    def plot_preprocessing_stages(self, audio, title=\"\"):\n",
    "        \"\"\"\n",
    "        Visualize before/after at each preprocessing stage.\n",
    "        \"\"\"\n",
    "        fig, axes = plt.subplots(5, 2, figsize=(14, 12))\n",
    "        \n",
    "        stages = [\n",
    "            (\"Original\", audio),\n",
    "            (\"After Heart Removal\", self.remove_heart_sounds(audio)),\n",
    "            (\"After Noise Removal\", self.remove_stationary_noise(audio)),\n",
    "        ]\n",
    "        \n",
    "        audio_cough = self.remove_stationary_noise(audio)\n",
    "        cough_mask, segments = self.detect_coughs(audio_cough)\n",
    "        audio_cough = self.remove_coughs(audio_cough, segments)\n",
    "        stages.append((\"After Cough Removal\", audio_cough))\n",
    "        \n",
    "        audio_final = self.preprocess(audio, verbose=False)\n",
    "        stages.append((\"Final Output\", audio_final))\n",
    "        \n",
    "        for idx, (stage_name, audio_stage) in enumerate(stages):\n",
    "            # Waveform\n",
    "            ax = axes[idx, 0]\n",
    "            t = np.linspace(0, len(audio_stage)/self.sr, len(audio_stage))\n",
    "            ax.plot(t, audio_stage, linewidth=0.5, color='steelblue')\n",
    "            ax.set_title(f\"{stage_name} - Waveform\", fontweight='bold')\n",
    "            ax.set_ylabel('Amplitude')\n",
    "            if idx == len(stages) - 1:\n",
    "                ax.set_xlabel('Time (s)')\n",
    "            \n",
    "            # Spectrogram\n",
    "            ax = axes[idx, 1]\n",
    "            D = librosa.stft(audio_stage)\n",
    "            S_db = librosa.power_to_db(np.abs(D)**2, ref=np.max)\n",
    "            img = librosa.display.specshow(S_db, sr=self.sr, hop_length=self.hop_length,\n",
    "                                          ax=ax, x_axis='time' if idx == len(stages)-1 else None,\n",
    "                                          y_axis='hz')\n",
    "            ax.set_title(f\"{stage_name} - Spectrogram\", fontweight='bold')\n",
    "            if idx == 0:\n",
    "                plt.colorbar(img, ax=ax, format='%+2.0f dB')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'preprocessing_stages_{title}.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icbhi-ast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
